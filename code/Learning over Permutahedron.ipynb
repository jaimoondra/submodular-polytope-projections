{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.path import Path\n",
    "from matplotlib import rc\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools \n",
    "from gurobipy import*\n",
    "from time import process_time\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_vector(v):\n",
    "    return np.array([v[k] for k in sorted(list(v.keys()))])\n",
    "\n",
    "def construct_function(n,g):\n",
    "    ground_set = list(range(1,n+1))\n",
    "    discrete_concave = sorted(g,reverse =True)\n",
    "    h = {}\n",
    "    h[0] = 0\n",
    "    for i,j in enumerate(discrete_concave):\n",
    "        h[i+1] = h[i] + j\n",
    "    return h\n",
    "\n",
    "def submodular_function(n,g):\n",
    "    \n",
    "    func = construct_function(n,g)\n",
    "    ground = list(range(1,n+1))\n",
    "    \n",
    "    def findsubsets(s, l): \n",
    "        return list(itertools.combinations(s, l)) \n",
    "\n",
    "    subsets = []\n",
    "    for i in range(1,n+1):\n",
    "        subsets.extend(findsubsets(ground, i))\n",
    "        \n",
    "    f = {}\n",
    "    f[tuple([0])] = func[0]\n",
    "    for i in subsets:\n",
    "        f[i] = func[len(i)]\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def submodular_oracle(S,func,card):\n",
    "    if card == True:\n",
    "        return func[len(S)]\n",
    "    else:\n",
    "        return func[S]\n",
    "    \n",
    "def greedy_submodular(w,func,card):\n",
    "    \n",
    "    #find permuation corresponding to cost vector sorted in decreasing order\n",
    "    pi = np.argsort(-w)+1\n",
    "    \n",
    "    #s is the optimal chain of elements in ground set and x is the corresponsing optimal solution constructed by greedy\n",
    "    x = {}\n",
    "    s = {}\n",
    "    s[0] = []\n",
    "    for i,j in enumerate(pi):\n",
    "        #extend chain based on permuation above\n",
    "        s[i+1] = sorted(pi[:i+1])\n",
    "        \n",
    "        #x is then the marginal gain\n",
    "        if w[j-1] > 0:\n",
    "            x[j] = submodular_oracle(tuple(s[i+1]),func,card) - submodular_oracle(tuple(s[i]),func,card)\n",
    "        else:\n",
    "            x[j] = 0\n",
    "        \n",
    "    return sort_vector(x)\n",
    "\n",
    "def greedy_submodular_base(w,func,card):\n",
    "    \n",
    "    #find permuation corresponding to cost vector sorted in decreasing order\n",
    "    pi = np.argsort(-w)+1\n",
    "    \n",
    "    #s is the optimal chain of elements in ground set and x is the corresponsing optimal solution constructed by greedy\n",
    "    x = {}\n",
    "    s = {}\n",
    "    s[0] = [0]\n",
    "    for i,j in enumerate(pi):\n",
    "        #extend chain based on permuation above\n",
    "        s[i+1] = sorted(pi[:i+1])\n",
    "        \n",
    "        #x is then the marginal gain\n",
    "        x[j] = submodular_oracle(tuple(s[i+1]),func,card) - submodular_oracle(tuple(s[i]),func,card)\n",
    "        \n",
    "    return sort_vector(x)\n",
    "\n",
    "def greedy_submodular_chains(w,func,chains):\n",
    "    \n",
    "    #find permuation corresponding to cost vector sorted in decreasing order\n",
    "    chains_new = chains + [list(np.ones(len(w)))]\n",
    "    pi = []\n",
    "    c_old = np.zeros(len(w))\n",
    "    pi_prime = np.argsort(-w)\n",
    "    for c in chains_new:\n",
    "        c_new = np.array(c) - c_old\n",
    "        s = list(np.where(c_new == 1)[0])\n",
    "        for i in pi_prime:\n",
    "            if i in s:\n",
    "                pi.append(int(i)+1)\n",
    "        c_old = c\n",
    "                \n",
    "    #s is the optimal chain of elements in ground set and x is the corresponsing optimal solution constructed by greedy\n",
    "    x = {}\n",
    "    s = {}\n",
    "    s[0] = []\n",
    "    k = int(sum(chains[-1]))\n",
    "    for i,j in enumerate(pi):\n",
    "        #extend chain based on permuation above\n",
    "        s[i+1] = sorted(pi[:i+1])\n",
    "        \n",
    "        #x is then the marginal gain\n",
    "        if w[j-1] >= 0 or i +1 <=k :\n",
    "            x[j] = submodular_oracle(tuple(s[i+1]),func,card) - submodular_oracle(tuple(s[i]),func,card)\n",
    "        else:\n",
    "            x[j] = 0\n",
    "        \n",
    "    return sort_vector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_card(x_0,a,func):\n",
    "    n = len(x_0)\n",
    "    card = True\n",
    "\n",
    "    #check if all components of LS direction are negative since in this case result is trivial\n",
    "    if all(a <0):\n",
    "        lam = 0\n",
    "\n",
    "    #otherwise we run discrete Newtons method for LS    \n",
    "    else:\n",
    "\n",
    "        #find initial lam based on singletons in the ground set; also gives check if a is feasible direction to begin with\n",
    "        lam = min([(submodular_oracle([i+1],func,card) - x_0[i])/j for i,j in enumerate(a) if j > 0])\n",
    "        \n",
    "        #we only need to do n iterations since our polytope is cardinality based\n",
    "        for i in range(len(x_0)):\n",
    "            #try moving with magnitued lam\n",
    "            y = x_0 + lam*a\n",
    "\n",
    "            #sort y so we can check feasiblity in the base polytope\n",
    "            pi = np.argsort(-y)+1\n",
    "            \n",
    "            #find cummulative sums of sorted vector so we can check feasibility/violations\n",
    "            s = np.cumsum(sorted(y,reverse =True))\n",
    "            violations = [func[i+1] - j for i,j in enumerate(s)]\n",
    "            \n",
    "            #find maximum violation and most violated set\n",
    "            card_violated,violation_value = min(enumerate(violations), key=lambda x : x[1])\n",
    "            #card_violated = min([i+1 for i,j in enumerate(violations) if j == violation_value])\n",
    "            \n",
    "            \n",
    "            #if smallest violation is 0 (note they can't all be strictly greater than 0  because of base polytope)\n",
    "            if np.round(violation_value,4) == 0:\n",
    "                break\n",
    "                \n",
    "            #otherwise we update step size and repeat\n",
    "            else:\n",
    "                most_violated_set = pi[:card_violated+1]\n",
    "                lam = (submodular_oracle(most_violated_set,func,card) - sum([x_0[i-1] for i in most_violated_set]))\\\n",
    "                        /sum([a[i-1] for i in most_violated_set])\n",
    "                \n",
    "    #note that if the sum of a != 0, then a will not satisfy base constraint, i.e. its not a feasbile direction\n",
    "    #So if a is a feasbile direction for the polymatroid but not for the base polytope ground set V will\n",
    "    #be the most violated in one of the iterations above. Thus, since x_0 \\in B(f) we know that x(V) = f(V) \n",
    "    # and hence when updating lam the numerator will be 0 for the iteration which would then give that lam = 0\n",
    "    # this shows the correctness of the algorithm and our construction of the violation for base constraint\n",
    "    return lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicator(S,n):\n",
    "    dic = {k:0 for k in range(1,n+1)}\n",
    "    for i in S:\n",
    "        dic[i] = 1\n",
    "    return sort_vector(dic)\n",
    "\n",
    "def get_tight_sets(x,func):\n",
    "    tight_sets = []\n",
    "    s = np.cumsum(sorted(x,reverse =True))\n",
    "    pi = np.argsort(-x)+1\n",
    "    slack = [func[i+1] - j for i,j in enumerate(s)]\n",
    "    for i,j in enumerate(slack):\n",
    "        if np.round(j,4) > 0:\n",
    "            continue\n",
    "        else:\n",
    "            tight_sets.append(get_indicator(pi[:i+1],n))\n",
    "            \n",
    "    return tight_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line-search using golden-section rule\n",
    "def segment_search(f, grad_f, x, y, tol=1e-6, stepsize=True):\n",
    "    \n",
    "    '''\n",
    "    Minimizes f over [x, y], i.e., f(x+gamma*(y-x)) as a function of scalar gamma in [0,1]\n",
    "    '''\n",
    "    \n",
    "    # restrict segment of search to [x, y]\n",
    "    d = (y-x).copy()\n",
    "    left, right = x.copy(), y.copy()\n",
    "    \n",
    "    # if the minimum is at an endpoint\n",
    "    if np.dot(d, grad_f(x))*np.dot(d, grad_f(y)) >= 0:\n",
    "        if f(y) <= f(x):\n",
    "            return y, 1\n",
    "        else:\n",
    "            return x, 0\n",
    "    \n",
    "    # apply golden-section method to segment\n",
    "    gold = (1+np.sqrt(5))/2\n",
    "    improv = np.inf\n",
    "    while improv > tol:\n",
    "        old_left, old_right = left, right\n",
    "        new = left+(right-left)/(1+gold)\n",
    "        probe = new+(right-new)/2\n",
    "        if f(probe) <= f(new):\n",
    "            left, right = new, right\n",
    "        else:\n",
    "            left, right = left, probe\n",
    "        improv = np.linalg.norm(f(right)-f(old_right))+np.linalg.norm(f(left)-f(old_left))\n",
    "    x_min = (left+right)/2\n",
    "    \n",
    "    # compute step size gamma\n",
    "    gamma = 0\n",
    "    if stepsize == True:\n",
    "        for i in range(len(d)):\n",
    "            if d[i] != 0:\n",
    "                gamma = (x_min[i]-x[i])/d[i]\n",
    "                break\n",
    "                \n",
    "    return x_min, gamma\n",
    "\n",
    "\n",
    "#Fucntion to compute away vertex\n",
    "def away_step(grad, S):\n",
    "    costs = {}\n",
    "    \n",
    "    for k,v in S.items():\n",
    "        cost = np.dot(k,grad)\n",
    "        costs[cost] = [k,v]\n",
    "    vertex, alpha = costs[max(costs.keys())]  \n",
    "    return vertex,alpha\n",
    "\n",
    "#Function to update active set\n",
    "def update_S(S,gamma, Away, vertex):\n",
    "    \n",
    "    S = S.copy()\n",
    "    vertex = tuple(vertex)\n",
    "    \n",
    "    if not Away:\n",
    "        if vertex not in S.keys():\n",
    "            S[vertex] = gamma\n",
    "        else:\n",
    "            S[vertex] *= (1-gamma)\n",
    "            S[vertex] += gamma\n",
    "            \n",
    "        for k in S.keys():\n",
    "            if k != vertex:\n",
    "                S[k] *= (1-gamma)\n",
    "    else:\n",
    "        for k in S.keys():\n",
    "            if k != vertex:\n",
    "                S[k] *= (1+gamma)\n",
    "            else:\n",
    "                S[k] *= (1+gamma)\n",
    "                S[k] -= gamma\n",
    "    return {k:v for k,v in S.items() if np.round(v,6) > 0}\n",
    "\n",
    "\n",
    "def line_search(x, d, gamma_max,func):\n",
    "\n",
    "    def fun(gamma):\n",
    "        ls = x + gamma*d\n",
    "        return func(ls)\n",
    "\n",
    "    res = minimize_scalar(fun, bounds=(0, gamma_max), method='bounded')\n",
    "\n",
    "    gamma = res.x\n",
    "    ls = x + gamma*d        \n",
    "    return ls, gamma\n",
    "\n",
    "\n",
    "#AFW Algorithm\n",
    "def AFW(x, S, lmo, epsilon,func,grad_f, f_tol, time_tol):\n",
    "    \n",
    "    #record primal gap, function value, and time every iteration\n",
    "    now=datetime.datetime.now()\n",
    "    primal_gap = []\n",
    "    function_value=[func(x)]\n",
    "    time = [0]\n",
    "    f_improv = np.inf\n",
    "\n",
    "    #initialize starting point and active set\n",
    "    t = 0    \n",
    "\n",
    "    while f_improv > f_tol and time[-1] < time_tol:\n",
    "        \n",
    "        start = process_time()\n",
    "        \n",
    "        #compute gradient\n",
    "        grad = grad_f(x)\n",
    "\n",
    "        #solve linear subproblem and compute FW direction\n",
    "        v = lmo(grad)\n",
    "        d_FW = v-x\n",
    "\n",
    "        #If primal gap is small enough - terminate\n",
    "        if np.dot(-grad,d_FW) <= epsilon:\n",
    "            break\n",
    "        else:\n",
    "            #update convergence data\n",
    "            primal_gap.append(np.dot(-grad,d_FW))\n",
    "\n",
    "        #Compute away vertex and direction\n",
    "        a,alpha_a = away_step(grad, S)\n",
    "        d_A = x - a\n",
    "\n",
    "        #Check if FW gap is greater than away gap\n",
    "        if np.dot(-grad,d_FW) >= np.dot(-grad,d_A):\n",
    "            #choose FW direction\n",
    "            d = d_FW\n",
    "            vertex = v\n",
    "            gamma_max = 1\n",
    "            Away = False\n",
    "        else:\n",
    "            #choose Away direction\n",
    "            d = d_A\n",
    "            vertex = a\n",
    "            gamma_max = alpha_a/(1-alpha_a)\n",
    "            Away = True\n",
    "\n",
    "        #Update next iterate by doing a feasible line-search\n",
    "        x, gamma = line_search(x, d, gamma_max,func)\n",
    "        #x, gamma = segment_search(func, grad_f, x, x + gamma_max *d)\n",
    "\n",
    "        #update active set\n",
    "        S = update_S(S,gamma, Away, vertex)\n",
    "        \n",
    "        end = process_time()\n",
    "        time.append(time[t] + end - start)\n",
    "        \n",
    "        f_improv = function_value[-1] - func(x)\n",
    "        function_value.append(func(x))\n",
    "        \n",
    "        t+=1\n",
    "        \n",
    "    return x, function_value, time,t,primal_gap,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull_correction1(S, func):    \n",
    "\n",
    "    M = np.array([np.array(i) for i in S])\n",
    "    \n",
    "    def fun(theta):\n",
    "        return func(np.dot(M.T,theta))\n",
    "\n",
    "    cons = ({'type': 'eq', 'fun': lambda theta: sum(theta) - 1}) #sum of theta = 1\n",
    "    bnds = tuple([(0, 1) for _ in M])\n",
    "    x0 = tuple([1/len(M) for _ in M])\n",
    "\n",
    "    res = minimize(fun, x0, bounds=bnds, constraints=cons)\n",
    "    \n",
    "    final_S = {tuple(M[i]):res.x[i] for i in range(len(M)) if np.round(res.x[i],5) > 0}\n",
    "\n",
    "    return np.dot(M.T,res.x),final_S\n",
    "\n",
    "\n",
    "def convex_hull_correction2(S,q):    \n",
    "\n",
    "    M = np.array([np.array(i) for i in S])\n",
    "   \n",
    "    opt, theta = projection_oracle_vertices(M,q)\n",
    "    \n",
    "    final_S = {tuple(M[i]):theta[i] for i in range(len(M))if np.round(theta[i],5) > 0}\n",
    "\n",
    "    return opt, final_S\n",
    "\n",
    "\n",
    "def proj_oracle(vertices,y):\n",
    "    m = Model(\"opt\")\n",
    "    n = len(vertices[0])\n",
    "    \n",
    "    #define variables\n",
    "    lam = {}\n",
    "    for i in range(len(vertices)):\n",
    "        lam[i] = m.addVar(lb=0, name='lam_{}'.format(i))\n",
    "    \n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        x.append(m.addVar(lb=-GRB.INFINITY, name='x_{}'.format(i)))\n",
    "    x = np.array(x)\n",
    "    m.update()\n",
    "\n",
    "    objExp = 0.5* np.dot(x-y, x-y)\n",
    "    m.setObjective(objExp, GRB.MINIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    #feasibility constraints\n",
    "    for i in range(n):\n",
    "        m.addConstr(x[i],'=', sum([lam[j]*vertices[j][i] for j in range(len(vertices))]))\n",
    "\n",
    "    #convex hull constraint\n",
    "    m.addConstr(quicksum([lam[i] for i in lam.keys()]), '=',1)\n",
    "    m.update()\n",
    "    \n",
    "    #optimize\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "    m.write('exact.lp')\n",
    "    m.optimize()\n",
    "    return np.array([i.x for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_tight(y,g):\n",
    "    \n",
    "    #sort y so we can check feasiblity in the base polytope\n",
    "    pi = np.argsort(-y)+1\n",
    "\n",
    "    #find cummulative sums of sorted vector so we can check feasibility/violations\n",
    "    s = np.cumsum(sorted(y,reverse =True))\n",
    "    violations = np.round(np.array([g[i+1] - j for i,j in enumerate(s)]),6)\n",
    "    \n",
    "    if any (violations < 0):\n",
    "        return 'y not feasible'\n",
    "    elif all(violations > 0):\n",
    "        return [0]\n",
    "    else:\n",
    "        return pi[:np.arange(len(y))[violations==0][-1]+1]\n",
    "    \n",
    "def proj(x):\n",
    "    return 0.5*np.dot(x - y,x-y)\n",
    "    \n",
    "def proj_grad(x):\n",
    "    return x - y\n",
    "\n",
    "def chi(M):\n",
    "    chi_0 = np.zeros(n)\n",
    "    for i in M:\n",
    "        chi_0[i-1] = 1\n",
    "    return chi_0\n",
    "\n",
    "def f(s):\n",
    "    return sum([n + 1 - i for i in range(1,s+1)])\n",
    "\n",
    "def compute_M(N,x):\n",
    "    return N[np.round(proj_grad(x)[N - 1],5) == np.round(np.min(proj_grad(x)[N - 1]),5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_oracle(A1,A2,b1,b2, c):\n",
    "    \n",
    "    '''\n",
    "    General form LP solver that solves min c^Tx subject to Ax <= b\n",
    "    '''\n",
    "\n",
    "    m = Model(\"opt\")\n",
    "    n = len(A.T)\n",
    "\n",
    "    #define variables\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        x.append(m.addVar(lb=-GRB.INFINITY, name='x_{}'.format(i)))\n",
    "\n",
    "    m.update()              \n",
    "\n",
    "    objExp = np.dot(np.array(x),c)\n",
    "    m.setObjective(objExp, GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    #feasibility constraints\n",
    "    for i in range(len(A1)):\n",
    "        m.addConstr(np.dot(np.array(x),A1[i]),'<=', b1[i])\n",
    "        \n",
    "    for i in range(len(A2)):\n",
    "        m.addConstr(np.dot(np.array(x),A2[i]),'==', b2[i])\n",
    "\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    #convex hull constraint\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    #optimize\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "    m.optimize()\n",
    "\n",
    "    return np.array([i.x for i in x]), m.Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_FW(x, lmo, T, grad_f, G = None):\n",
    "    \n",
    "    #record primal gap, function value, and time every iteration\n",
    "    time = [0]\n",
    "    grad_list = [np.zeros(len(x))]\n",
    "\n",
    "    #initialize starting point and active set\n",
    "    t = 1\n",
    "    x_t= [x]\n",
    "    v_t = {}\n",
    "    loss = []\n",
    "    \n",
    "    #define blocksizes and random sampling parameters\n",
    "    k = int(np.ceil(T**(1/3)))\n",
    "    \n",
    "    if G:\n",
    "        delta  = 2/(G*len(x)**0.5 * k**2)\n",
    "    else:\n",
    "        delta  = 2/(len(x)**1.5 * k**2)\n",
    "\n",
    "    while t <= T:\n",
    "        \n",
    "        start = datetime.datetime.now()\n",
    "        \n",
    "        if t%k != 0:\n",
    "            \n",
    "            #play x_{t-1}, i.e. dont do anything\n",
    "            x_t.append(x_t[-1])\n",
    "            \n",
    "            #observe gradient/loss\n",
    "            grad = grad_f(x_t[-1])\n",
    "            grad_list.append(grad)\n",
    "            \n",
    "            #compute loss\n",
    "            loss.append(np.dot(x_t[-1],grad))\n",
    "            \n",
    "        else:\n",
    "            v = []\n",
    "            for i in range(k):\n",
    "                v_ = np.random.normal(0,1,n)\n",
    "                v.append(v_/np.linalg.norm(v_))\n",
    "            v = np.array(v)\n",
    "            grad_sum = np.sum(np.array(grad_list),axis = 0)\n",
    "            x = np.array([lmo(grad_sum + v[j]/delta) for j in range(k)])\n",
    "            \n",
    "            #play average of x\n",
    "            x_t.append(np.mean(x,axis = 0))\n",
    "            \n",
    "            #observe gradient/loss\n",
    "            grad = grad_f(x_t[-1])\n",
    "            grad_list.append(grad)\n",
    "            \n",
    "            #compute loss\n",
    "            loss.append(np.dot(x_t[-1],grad))\n",
    "\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        time.append(time[t-1] + (end - start).total_seconds())\n",
    "        \n",
    "        t+=1\n",
    "        \n",
    "    return x_t, time, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1, 3, 2]),\n",
       "  array([1, 3, 2]),\n",
       "  array([1, 3, 2]),\n",
       "  array([1.33333333, 2.        , 2.66666667]),\n",
       "  array([1.33333333, 2.        , 2.66666667]),\n",
       "  array([1.33333333, 2.        , 2.66666667]),\n",
       "  array([1.66666667, 2.        , 2.33333333]),\n",
       "  array([1.66666667, 2.        , 2.33333333]),\n",
       "  array([1.66666667, 2.        , 2.33333333]),\n",
       "  array([2.        , 1.33333333, 2.66666667]),\n",
       "  array([2.        , 1.33333333, 2.66666667])],\n",
       " [0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.000967,\n",
       "  0.000967,\n",
       "  0.000967,\n",
       "  0.000967,\n",
       "  0.000967,\n",
       "  0.000967,\n",
       "  0.002087,\n",
       "  0.002087],\n",
       " [-3.1293528667551067,\n",
       "  -1.5382371285976213,\n",
       "  -1.4248182097092061,\n",
       "  -2.7634166995210063,\n",
       "  -0.16005419157112577,\n",
       "  -5.348056956999331,\n",
       "  -6.3543301842905935,\n",
       "  -3.0087583524776367,\n",
       "  -3.5099786250002,\n",
       "  -1.7686446680665506])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permutahedron\n",
    "def f(s):\n",
    "    return sum([n + 1 - i for i in range(1,s+1)])\n",
    "g = {i:f(i) for i in range(1,n+1)}\n",
    "g[0] = 0\n",
    "\n",
    "\n",
    "#define projection points\n",
    "q = np.abs(np.random.normal(0,3,n))\n",
    "    \n",
    "#define projection function and its gradient\n",
    "f = lambda x: 0.5*np.dot(x-q,x-q)\n",
    "grad_f = lambda x: np.power(x- q,1) + np.random.normal(0,1/n**1,n)\n",
    "\n",
    "\n",
    "#define greedy linear optimization oracle\n",
    "lmo = lambda w: greedy_submodular_chains(w,g,[np.ones(len(w))])\n",
    "\n",
    "#initialize algorithm with arbitrary vertex and point to project\n",
    "w = np.random.choice(range(1,n+1), size=n, replace=False)\n",
    "card = True\n",
    "x  = lmo(w)\n",
    "T = 10\n",
    "\n",
    "online_FW(x, lmo, T, grad_f, G = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}