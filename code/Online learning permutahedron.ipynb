{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, minimize_scalar\n",
    "from gurobipy import *\n",
    "import numpy.linalg as npl\n",
    "from time import process_time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants:\n",
    "base_decimal_accuracy = 5  # All inputs and outputs will have this accuracy\n",
    "minimum_decimal_difference = math.pow(10, -base_decimal_accuracy)  # for float accuracy\n",
    "high_decimal_accuracy = 12  # Used only by inner computations in algorithms\n",
    "dist_square = 50  # todo: add description\n",
    "std_dev_point = 5  # Standard deviation for selection on random point\n",
    "seeds = [1234, 90, 0, 6454, 6, 444444, 39256, 7527, 50604, 24743, 47208, 28212, 19019, 41225, 23406,\n",
    "         52847, 62727, 3034, 55949, 13206, 8086, 55396, 21709, 10223, 41131, 45982, 51335, 19036,\n",
    "         9056, 17681, 15141, 6306, 63724, 42770, 35394, 44056, 22564, 50203, 13494, 2617, 62882,\n",
    "         35918, 2597, 43039, 7228, 35110, 63328, 35294, 21347, 69, 55129, 64711, 24826, 25899,\n",
    "         13623, 64414, 18845, 51362, 15405, 39271, 29175, 31418, 3071, 9840, 49312, 63306, 48069,\n",
    "         48216, 59896, 52064, 7533, 9390, 36907, 25146, 7840, 42243, 35634, 50032, 12157, 47424,\n",
    "         39071, 9496, 30727, 11739, 60247, 33845, 25754, 45533, 27374, 29006, 3133, 8072, 6823,\n",
    "         55874, 54767, 29723, 50573, 19110, 40861, 17731, 20386, 54415, 11486, 63471, 26744, 3881]\n",
    "# Multiple seeds to ensure both randomness and repeatability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def round_list(x, accuracy: int = base_decimal_accuracy):\n",
    "    \"\"\"\n",
    "    Round a list of numbers to appropriate accuracy\n",
    "    :param x: List of numbers\n",
    "    :param accuracy: Number of decimal digits to round float numbers to\n",
    "    :return: List of rounded numbers\n",
    "    \"\"\"\n",
    "    x = [round(i, accuracy) for i in x]\n",
    "    return x\n",
    "\n",
    "\n",
    "def sort(x, reverse=False):\n",
    "    \"\"\"\n",
    "    :param x: List of numbers\n",
    "    :param reverse: Sorts in decreasing order if set to True\n",
    "    :return: Sorted list and the corresponding mapping (permutation)\n",
    "    \"\"\"\n",
    "    enum = sorted(enumerate(x), key=lambda z: z[1], reverse=reverse)\n",
    "    y = [enum[j][1] for j in range(len(enum))]\n",
    "    mapping = {enum[j][0]: j for j in range(len(enum))}\n",
    "\n",
    "    return y, mapping\n",
    "\n",
    "\n",
    "def invert(mapping):\n",
    "    \"\"\"\n",
    "    Invert a (bijective) mapping {0, ..., n - 1} -> {0, ..., n - 1}\n",
    "    :param mapping: Original mapping\n",
    "    :return: Inverse of the original mapping\n",
    "    \"\"\"\n",
    "    return {mapping[i]: i for i in range(len(mapping))}\n",
    "\n",
    "\n",
    "def map_set(S, mapping):\n",
    "    \"\"\"\n",
    "    Determines the range of S under mapping\n",
    "    :param S: set of integers\n",
    "    :param mapping: mapping\n",
    "    :return: range of S under mapping as a set\n",
    "    \"\"\"\n",
    "    return set({mapping[i] for i in S})\n",
    "\n",
    "\n",
    "def permute(x, mapping):\n",
    "    \"\"\"\n",
    "    Permutes x according to mapping\n",
    "    :param x:\n",
    "    :param mapping:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y = [0.0] * len(x)\n",
    "    for i in range(len(x)):\n",
    "        y[mapping[i]] = x[i]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def generate_random_permutation(n: int):\n",
    "    A = list(range(n + 1)[1: n + 1])\n",
    "    random.shuffle(A)\n",
    "    return A\n",
    "\n",
    "\n",
    "def determine_tight_sets(y, x, g=None):\n",
    "    \"\"\"\n",
    "    Given a point y and its projection x, determines the tight sets\n",
    "    :param y: projected point, np array\n",
    "    :param x: projection, np array\n",
    "    :return: sequence of tight cuts alogn with c[j + 1] - c[j] value, sorted in decreasing order\n",
    "    of values of c[j + 1] - c[j]\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(x)\n",
    "    z = x - y\n",
    "    z1, mapping = sort(list(z))\n",
    "    inverse_mapping = invert(mapping)\n",
    "\n",
    "    tight_sets = []\n",
    "\n",
    "    flag = np.zeros(len(z1))\n",
    "    for i in range(1, len(z1)):\n",
    "        if abs(z1[i] - z1[i - 1]) >= 0.000001:\n",
    "            flag[i] = 1\n",
    "\n",
    "    H, F = set(), set()\n",
    "    for i in range(n):\n",
    "        if flag[i] == 1:\n",
    "            tight_sets.append([z1[i] - z1[i - 1], frozenset(H)])\n",
    "            F = {inverse_mapping[i]}\n",
    "        else:\n",
    "            F = F.union({inverse_mapping[i]})\n",
    "        H = H.union({inverse_mapping[i]})\n",
    "\n",
    "    tight_sets.append([np.inf, frozenset(H)])\n",
    "\n",
    "    tight_sets = np.array(tight_sets)\n",
    "    tight_sets = tight_sets[np.argsort(tight_sets[:, 0])]\n",
    "\n",
    "    return tight_sets[::-1]\n",
    "\n",
    "\n",
    "def generate_concave_function(n: int, seed=None):\n",
    "    \"\"\"\n",
    "    Return a 'random' concave function\n",
    "    :param n: Dimension of the ground set\n",
    "    :param seed: Seed for random number generators\n",
    "    :return: A concave function (a.k.a. cardinality function)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    g = random_point(n, 1, True, seed)\n",
    "    g = [round(x, base_decimal_accuracy) for x in g]\n",
    "    g.sort(reverse=True)\n",
    "\n",
    "    for i in range(1, len(g)):\n",
    "        g[i] = g[i - 1] + g[i]\n",
    "\n",
    "    g = round_list(g, base_decimal_accuracy)\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def plot_iterates(iterates, y, color1, color2):\n",
    "    \"\"\"\n",
    "    Plot for iterates of the inc-fix algorithm.\n",
    "    x-axis: elements of the ground set, in increasing order (0, 1, ..., N - 1)\n",
    "    y-axis: value of the iterate\n",
    "    That is, point (n, v_n) represents the value of point v = (v_0, ..., v_{N - 1}) at coordinate n.\n",
    "    Several iterates are plotted in the same figure, with the original point y in a different color.\n",
    "    :param iterates: List of points (iterates)\n",
    "    :param y: The original point y\n",
    "    :param color1, color2: first color. One of 'r', 'g', 'c' etc. See https://matplotlib.org/2.0.2/api/colors_api.html\n",
    "    for the full list.\n",
    "    \"\"\"\n",
    "    jump = max(int(n / 10), min(5, int(n / 2)))\n",
    "    for i in range(len(iterates)):\n",
    "        iterates[i] = round_list(iterates[i], base_decimal_accuracy)\n",
    "        if i % jump == 1 or i == len(iterates) - 1:\n",
    "            plt.plot(iterates[i], color1)\n",
    "\n",
    "    plt.xlabel('Ground set elements')\n",
    "    plt.ylabel('Value')\n",
    "    plt.plot(y, color2)\n",
    "\n",
    "\n",
    "def plot_tight_sets(tight_sets, color1):\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Tight set size')\n",
    "    plt.plot(tight_sets, color1)\n",
    "\n",
    "\n",
    "def random_point(n: int, mean: float = 0, r: float = 1, nonnegative: bool = False, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # z = np.random.randint(1, n, n)\n",
    "    z = np.random.multivariate_normal(mean=[mean] * n, cov=(r * r) * np.identity(n))\n",
    "    if nonnegative:\n",
    "        z = [abs(round(x, 2)) for x in z]\n",
    "    else:\n",
    "        z = [round(x, 2) for x in z]\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "def random_error(n: int, r: float = 1, seed=None, decial_accuracy: int = base_decimal_accuracy):\n",
    "    \"\"\"\n",
    "    Generates random error vector in dimension n, where each coordinate is from a Gaussian\n",
    "    distribiution with mean 0 and standard deviation r\n",
    "    :param n: dimension\n",
    "    :param r: standrad deviation in each coordinate\n",
    "    :param seed: random seed\n",
    "    :param decial_accuracy: number of digists after the decimal point\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    z = np.random.multivariate_normal(mean=[0] * n, cov=(r * r) * np.identity(n))\n",
    "    return [round(x, decial_accuracy) for x in z]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def active_set_oracle(vertices, x):\n",
    "    try:\n",
    "        m = Model(\"opt\")\n",
    "        vertices = list(vertices)\n",
    "        n = len(vertices[0])\n",
    "\n",
    "        # define variables\n",
    "        lam = {}\n",
    "        for i in range(len(vertices)):\n",
    "            lam[i] = m.addVar(lb=0, name='lam_{}'.format(i),obj = 1)\n",
    "\n",
    "        # feasibility constraints\n",
    "        for i in range(n):\n",
    "            m.addConstr(x[i],'=', sum([lam[j] * vertices[j][i] for j in range(len(vertices))]))\n",
    "\n",
    "        # convex hull constraint\n",
    "        m.addConstr(quicksum([lam[i] for i in lam.keys()]), '=',1)\n",
    "        m.update()\n",
    "\n",
    "        # optimize\n",
    "        m.setParam( 'OutputFlag', False )\n",
    "        # m.write('exact.lp')\n",
    "        m.optimize()\n",
    "        v = {}\n",
    "\n",
    "        for i in lam:\n",
    "            if np.round(lam[i].x,5) > 0:\n",
    "                v[tuple(vertices[i])] = lam[i].x\n",
    "\n",
    "        return True\n",
    "\n",
    "    except AttributeError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# line-search using golden-section rule\n",
    "def segment_search(f, grad_f, x, y, tol=1e-6, stepsize=True):\n",
    "    '''\n",
    "    Minimizes f over [x, y], i.e., f(x+gamma*(y-x)) as a function of scalar gamma in [0,1]\n",
    "    '''\n",
    "\n",
    "    # restrict segment of search to [x, y]\n",
    "    d = (y - x).copy()\n",
    "    left, right = x.copy(), y.copy()\n",
    "\n",
    "    # if the minimum is at an endpoint\n",
    "    if np.dot(d, grad_f(x)) * np.dot(d, grad_f(y)) >= 0:\n",
    "        if f(y) <= f(x):\n",
    "            return y, 1\n",
    "        else:\n",
    "            return x, 0\n",
    "\n",
    "    # apply golden-section method to segment\n",
    "    gold = (1 + np.sqrt(5)) / 2\n",
    "    improv = np.inf\n",
    "    while improv > tol:\n",
    "        old_left, old_right = left, right\n",
    "        new = left + (right - left) / (1 + gold)\n",
    "        probe = new + (right - new) / 2\n",
    "        if f(probe) <= f(new):\n",
    "            left, right = new, right\n",
    "        else:\n",
    "            left, right = left, probe\n",
    "        improv = np.linalg.norm(f(right) - f(old_right)) + np.linalg.norm(f(left) - f(old_left))\n",
    "    x_min = (left + right) / 2\n",
    "\n",
    "    # compute step size gamma\n",
    "    gamma = 0\n",
    "    if stepsize == True:\n",
    "        for i in range(len(d)):\n",
    "            if d[i] != 0:\n",
    "                gamma = (x_min[i] - x[i]) / d[i]\n",
    "                break\n",
    "\n",
    "    return x_min, gamma\n",
    "\n",
    "\n",
    "def line_search(x, d, gamma_max, func):\n",
    "    def fun(gamma):\n",
    "        ls = x + gamma * d\n",
    "        return func(ls)\n",
    "\n",
    "    res = minimize_scalar(fun, bounds=(0, gamma_max), method='bounded')\n",
    "\n",
    "    gamma = res.x\n",
    "    ls = x + gamma * d\n",
    "    return ls, gamma\n",
    "\n",
    "\n",
    "def AFW(x, S, lmo, epsilon, func, grad_f, f_tol, time_tol):\n",
    "    n = len(x)\n",
    "    # Fucntion to compute away vertex\n",
    "    def away_step(grad, S):\n",
    "        costs = {}\n",
    "\n",
    "        for k, v in S.items():\n",
    "            cost = np.dot(k, grad)\n",
    "            costs[cost] = [k, v]\n",
    "        vertex, alpha = costs[max(costs.keys())]\n",
    "        return vertex, alpha\n",
    "\n",
    "    def update_S(S, gamma, Away, vertex):\n",
    "        S = S.copy()\n",
    "        vertex = tuple(vertex)\n",
    "\n",
    "        if not Away:\n",
    "            if vertex not in S.keys():\n",
    "                S[vertex] = gamma\n",
    "            else:\n",
    "                S[vertex] *= (1 - gamma)\n",
    "                S[vertex] += gamma\n",
    "\n",
    "            for k in S.keys():\n",
    "                if k != vertex:\n",
    "                    S[k] *= (1 - gamma)\n",
    "        else:\n",
    "            for k in S.keys():\n",
    "                if k != vertex:\n",
    "                    S[k] *= (1 + gamma)\n",
    "                else:\n",
    "                    S[k] *= (1 + gamma)\n",
    "                    S[k] -= gamma\n",
    "        T = {k: v for k, v in S.items() if np.round(v, 10) > 0}\n",
    "        t = sum(list(T.values()))\n",
    "        T = {k: T[k]/t for k in T}\n",
    "        x = np.zeros(n)\n",
    "        for k in T:\n",
    "            x = x + np.array(k) * T[k]\n",
    "        return T\n",
    "\n",
    "        # return {k: v for k, v in S.items() if np.round(v, 12) > 0}\n",
    "\n",
    "    # record primal gap, function value, and time every iteration\n",
    "    now = datetime.datetime.now()\n",
    "    primal_gap = []\n",
    "    function_value = [func(x)]\n",
    "    time = [0]\n",
    "    f_improv = np.inf\n",
    "    # initialize starting point and active set\n",
    "    t = 0\n",
    "    while f_improv > f_tol and time[-1] < time_tol:\n",
    "        start = process_time()\n",
    "        # compute gradient\n",
    "        grad = grad_f(x)\n",
    "        # solve linear subproblem and compute FW direction\n",
    "        v = lmo(-grad)\n",
    "        d_FW = v - x\n",
    "        # If primal gap is small enough - terminate\n",
    "        if np.dot(-grad, d_FW) <= epsilon:\n",
    "            break\n",
    "        else:\n",
    "            # update convergence data\n",
    "            primal_gap.append(np.dot(-grad, d_FW))\n",
    "            logging.info(str(np.dot(-grad, d_FW)))\n",
    "            logging.debug(str(v))\n",
    "\n",
    "        # Compute away vertex and direction\n",
    "        a, alpha_a = away_step(grad, S)\n",
    "        d_A = x - a\n",
    "        # Check if FW gap is greater than away gap\n",
    "        if np.dot(-grad, d_FW) >= np.dot(-grad, d_A):\n",
    "            # choose FW direction\n",
    "            d = d_FW\n",
    "            vertex = v\n",
    "            gamma_max = 1\n",
    "            Away = False\n",
    "        else:\n",
    "            # choose Away direction\n",
    "            d = d_A\n",
    "            vertex = a\n",
    "            gamma_max = alpha_a / (1 - alpha_a)\n",
    "            Away = True\n",
    "        # Update next iterate by doing a feasible line-search\n",
    "        x, gamma = line_search(x, d, gamma_max, func)\n",
    "        # x, gamma = segment_search(func, grad_f, x, x + gamma_max *d)\n",
    "        # update active set\n",
    "        S = update_S(S, gamma, Away, vertex)\n",
    "        end = process_time()\n",
    "        time.append(time[t] + end - start)\n",
    "        f_improv = function_value[-1] - func(x)\n",
    "        function_value.append(func(x))\n",
    "        t += 1\n",
    "\n",
    "    return x, function_value, time, t, primal_gap, S\n",
    "\n",
    "\n",
    "def adaptive_AFW_cardinality_polytope(x, S, P, epsilon, func, grad_f, f_tol, time_tol,\n",
    "                                      initial_tight_sets, y):\n",
    "    \"\"\"\n",
    "    Adaptive AFW\n",
    "    :param x: initial vertex\n",
    "    :param S: initial active set\n",
    "    :param P: Submodular Polytope\n",
    "    :param epsilon: AFW-gap parameter\n",
    "    :param func: function to minimize (Euclidean distance in our case)\n",
    "    :param grad_f: gradient of func\n",
    "    :param f_tol:\n",
    "    :param time_tol: Max allowed time\n",
    "    :param initial_tight_sets: Known tight sets\n",
    "    :param y: point to be projected\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Fucntion to compute away vertex\n",
    "    n = len(x)\n",
    "    T = set(S.keys())\n",
    "    def away_step(grad, S):\n",
    "        costs = {}\n",
    "\n",
    "        for k, v in S.items():\n",
    "            cost = np.dot(k, grad)\n",
    "            costs[cost] = [k, v]\n",
    "        vertex, alpha = costs[max(costs.keys())]\n",
    "        return vertex, alpha\n",
    "\n",
    "    def update_S(S, gamma, Away, vertex):\n",
    "        S = S.copy()\n",
    "        vertex = tuple(vertex)\n",
    "\n",
    "        if not Away:\n",
    "            if vertex not in S.keys():\n",
    "                S[vertex] = gamma\n",
    "            else:\n",
    "                S[vertex] *= (1 - gamma)\n",
    "                S[vertex] += gamma\n",
    "\n",
    "            for k in S.keys():\n",
    "                if k != vertex:\n",
    "                    S[k] *= (1 - gamma)\n",
    "        else:\n",
    "            for k in S.keys():\n",
    "                if k != vertex:\n",
    "                    S[k] *= (1 + gamma)\n",
    "                else:\n",
    "                    S[k] *= (1 + gamma)\n",
    "                    S[k] -= gamma\n",
    "        T = {k: v for k, v in S.items() if np.round(v, 10) > 0}\n",
    "        t = sum(list(T.values()))\n",
    "        T = {k: T[k]/t for k in T}\n",
    "        x = np.zeros(n)\n",
    "        for k in T:\n",
    "            x = x + np.array(k) * T[k]\n",
    "        return T\n",
    "\n",
    "    def infer_tight_sets_from_close_point(d, tight_sets1):\n",
    "        \"\"\"\n",
    "        Infers tights sets for tilde(y) from tight sets for y\n",
    "        :param d: distance d(y, tilde(y))\n",
    "        :param tight_sets1: tight_sets of point y, along with their c[j + 1] - c[j] values,\n",
    "        sorted by their c[j + 1] - c[j] values\n",
    "        :return: inferred tight sets for tilde(y), list\n",
    "        \"\"\"\n",
    "        inferred_tight_sets = set()\n",
    "\n",
    "        for t in range(len(tight_sets1)):\n",
    "            a = tight_sets1[t]\n",
    "            if 2 * d < a[0]:\n",
    "                inferred_tight_sets.add(a[1])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return inferred_tight_sets\n",
    "\n",
    "    # record primal gap, function value, and time every iteration\n",
    "    now = datetime.datetime.now()\n",
    "    primal_gap = []\n",
    "    function_value = [func(x)]\n",
    "    time = [0]\n",
    "    f_improv = np.inf\n",
    "    t = 0\n",
    "    inferred_tight_sets = initial_tight_sets.union({frozenset()})\n",
    "\n",
    "    while f_improv > f_tol and time[-1] < time_tol:\n",
    "        start = process_time()              # Start time\n",
    "        grad = grad_f(x)                    # Compute gradient\n",
    "\n",
    "        # solve linear subproblem and compute FW direction\n",
    "        def lmo(c, inferred_tight_sets):\n",
    "            inferred_tight_sets_list = list(inferred_tight_sets)\n",
    "            inferred_tight_sets_list.sort(key=len)\n",
    "            _, v = P.linear_optimization_tight_sets(c, inferred_tight_sets_list)\n",
    "            return v\n",
    "\n",
    "        v = lmo(-grad, list(inferred_tight_sets))\n",
    "        d_FW = v - np.array(x)\n",
    "\n",
    "        gap = np.dot(-grad, d_FW)\n",
    "\n",
    "        if gap < 0:\n",
    "            gap = 0\n",
    "\n",
    "        d = 2 * math.sqrt(gap)\n",
    "        tight_sets = determine_tight_sets(y, x)\n",
    "        new_inferred_tight_sets = infer_tight_sets_from_close_point(d, tight_sets)\n",
    "        if not new_inferred_tight_sets.issubset(inferred_tight_sets):\n",
    "            inferred_tight_sets = inferred_tight_sets.union(new_inferred_tight_sets)\n",
    "            x = lmo(-grad, list(inferred_tight_sets))\n",
    "            T = T.union(S.keys())\n",
    "            # print(T)\n",
    "            S = {tuple(x): 1}\n",
    "            try:\n",
    "                x = cut_rounding(P, list(inferred_tight_sets), y, T)\n",
    "                end = process_time()\n",
    "                time.append(time[t] + end - start)\n",
    "                f_improv = function_value[-1] - func(x)\n",
    "                function_value.append(func(x))\n",
    "                t += 1\n",
    "                logging.warning('Rounded successfully!')\n",
    "                return x, function_value, time, t, primal_gap, S, inferred_tight_sets\n",
    "            except ValueError:\n",
    "                if gap <= epsilon:  # If primal gap is small enough - terminate\n",
    "                    break\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            if gap <= epsilon:                      # If primal gap is small enough - terminate\n",
    "                break\n",
    "            else:\n",
    "                primal_gap.append(gap)              # update convergence data\n",
    "                logging.info(str(gap))\n",
    "                logging.debug(str(v))\n",
    "\n",
    "            # Compute away vertex and direction\n",
    "            a, alpha_a = away_step(grad, S)\n",
    "            d_A = np.array(x) - np.array(a)\n",
    "\n",
    "            # Check if FW gap is greater than away gap\n",
    "            if np.dot(-grad, d_FW) >= np.dot(-grad, d_A):\n",
    "                d = d_FW                            # choose FW direction\n",
    "                vertex = v\n",
    "                gamma_max = 1\n",
    "                Away = False\n",
    "            else:\n",
    "                d = d_A                             # choose Away direction\n",
    "                vertex = a\n",
    "                gamma_max = alpha_a / (1 - alpha_a)\n",
    "                Away = True\n",
    "\n",
    "            # Update next iterate by doing a feasible line-search\n",
    "            x, gamma = line_search(x, d, gamma_max, func)\n",
    "\n",
    "            # update active set\n",
    "            S = update_S(S, gamma, Away, vertex)\n",
    "        end = process_time()\n",
    "        time.append(time[t] + end - start)\n",
    "        f_improv = function_value[-1] - func(x)\n",
    "        function_value.append(func(x))\n",
    "        t += 1\n",
    "\n",
    "    return x, function_value, time, t, primal_gap, S, inferred_tight_sets\n",
    "\n",
    "\n",
    "def convex_hull_correction1(S, func):\n",
    "    M = np.array([np.array(i) for i in S])\n",
    "\n",
    "    def fun(theta):\n",
    "        return func(np.dot(M.T, theta))\n",
    "\n",
    "    cons = ({'type': 'eq', 'fun': lambda theta: sum(theta) - 1})  # sum of theta = 1\n",
    "    bnds = tuple([(0, 1) for _ in M])\n",
    "    x0 = tuple([1 / len(M) for _ in M])\n",
    "\n",
    "    res = minimize(fun, x0, bounds=bnds, constraints=cons)\n",
    "\n",
    "    final_S = {tuple(M[i]): res.x[i] for i in range(len(M)) if np.round(res.x[i], 5) > 0}\n",
    "\n",
    "    return np.dot(M.T, res.x), final_S\n",
    "\n",
    "\n",
    "def convex_hull_correction2(S, q):\n",
    "    M = np.array([np.array(i) for i in S])\n",
    "\n",
    "    opt, theta = proj_oracle(M, q)\n",
    "\n",
    "    final_S = {tuple(M[i]): theta[i] for i in range(len(M)) if np.round(theta[i], 5) > 0}\n",
    "\n",
    "    return opt, final_S\n",
    "\n",
    "\n",
    "def proj_oracle(vertices, y):\n",
    "    m = Model(\"opt\")\n",
    "    n = len(vertices[0])\n",
    "\n",
    "    # define variables\n",
    "    lam = {}\n",
    "    for i in range(len(vertices)):\n",
    "        lam[i] = m.addVar(lb=0, name='lam_{}'.format(i))\n",
    "\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        x.append(m.addVar(lb=-GRB.INFINITY, name='x_{}'.format(i)))\n",
    "    x = np.array(x)\n",
    "    m.update()\n",
    "\n",
    "    objExp = 0.5 * np.dot(x - y, x - y)\n",
    "    m.setObjective(objExp, GRB.MINIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    # feasibility constraints\n",
    "    for i in range(n):\n",
    "        m.addConstr(x[i], '=', sum([lam[j] * vertices[j][i] for j in range(len(vertices))]))\n",
    "\n",
    "    # convex hull constraint\n",
    "    m.addConstr(quicksum([lam[i] for i in lam.keys()]), '=', 1)\n",
    "    m.update()\n",
    "\n",
    "    # optimize\n",
    "    m.setParam('OutputFlag', False)\n",
    "    # m.write('exact.lp')\n",
    "    m.optimize()\n",
    "    return np.array([i.x for i in x]), np.array([lam[i].x for i in lam])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online learning helpers and isotonic projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_loss_functions_for_permutahedron(a, b, seed, n: int, T: int):\n",
    "    \"\"\"\n",
    "    Generates loss functions\n",
    "    :param a: number of permutations\n",
    "    :param b: max swap distance between any two permutations\n",
    "    :param seed: seed for random\n",
    "    :param n: size of ground set\n",
    "    :param T: time (number of iterations in the online problem)\n",
    "    :return: loss function vectors\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    def generate_close_permutation():\n",
    "        sigma1 = np.array([sigma0[j] for j in range(n)])\n",
    "        for j in range(b):\n",
    "            c, d = np.random.randint(0, n), np.random.randint(0, n)\n",
    "            sigma1[c], sigma1[d] = sigma1[d], sigma1[c]\n",
    "\n",
    "        return sigma1\n",
    "\n",
    "    sigma0 = np.array(generate_random_permutation(n))\n",
    "    permutations = [sigma0]\n",
    "    for i in range(1, a):\n",
    "        sigma = generate_close_permutation()\n",
    "        permutations.append(sigma)\n",
    "\n",
    "    loss_vectors_list = []\n",
    "    for i in range(T):\n",
    "        x = [random.random() for i in range(n)]  # Each entry is random number between 0 and 1\n",
    "        s = sum(x)\n",
    "        x = round_list([(x[i] * n) / s for i in range(n)], 3)  # Normalize so the sum is always n\n",
    "        x.sort()\n",
    "\n",
    "        loss = [0.0] * n\n",
    "        t = np.random.randint(0, a)\n",
    "        sigma = permutations[t]\n",
    "        for j in range(n):\n",
    "            loss[j] = x[sigma[j] - 1]\n",
    "\n",
    "        loss_vectors_list.append(np.array(loss))\n",
    "\n",
    "    return loss_vectors_list\n",
    "\n",
    "\n",
    "def pool(values, weights, l, r, ):\n",
    "    new_point = sum(map(lambda x: values[x] * weights[x], range(l, r + 1))) / sum(weights[l: r + 1])\n",
    "    values[l] = new_point\n",
    "    weights[l] = sum(weights[l: r + 1])\n",
    "\n",
    "    return values[:l + 1], weights[:l + 1]\n",
    "\n",
    "\n",
    "def poolAdjacentViolators(input):\n",
    "    \"\"\"\n",
    "    Main function to solve the pool adjacent violator algorithm\n",
    "    on the given array of data.\n",
    "    This is a O(n) implementation. Trick is that while regersssing\n",
    "    if we see a violation, we average the numbers and instead of\n",
    "    storing them as two numbers, we store the number once and store\n",
    "    a corresponding weight. This way, for new numbers we don't have\n",
    "    to go back for each n, but only one place behind and update the\n",
    "    corresponding weights.\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    output = []\n",
    "\n",
    "    index = 0\n",
    "    while index < len(input):\n",
    "        temp = index\n",
    "\n",
    "        # Find monotonicity violating sequence, if any.\n",
    "        # Difference of temp-beg would be our violating range.\n",
    "        while temp < len(input) - 1 and input[temp] > input[temp + 1]:\n",
    "            # Append this number to the final output and set its weight to be 1.\n",
    "            temp += 1\n",
    "\n",
    "        if temp == index:\n",
    "            output_beg = len(output) - 1\n",
    "            output_end = output_beg + 1\n",
    "            output.append(input[index])\n",
    "            weights.append(1)\n",
    "            index += 1\n",
    "        else:\n",
    "            # Pool the violating sequence, if after violating monotonicity\n",
    "            # is broken, we need to fix the output array.\n",
    "            output_beg = len(output)\n",
    "            output_end = output_beg + temp - index\n",
    "            output.extend(input[index: temp + 1])\n",
    "            weights.extend([1] * (temp - index + 1))\n",
    "            index = temp + 1\n",
    "\n",
    "        # Fix the output to be in the increasing order.\n",
    "        while output_beg >= 0 and output[output_beg] > output[output_beg + 1]:\n",
    "            output, weights = pool(output, weights, output_beg, output_end)\n",
    "            diff = (output_end - output_beg)\n",
    "            output_beg -= 1\n",
    "            output_end -= diff\n",
    "\n",
    "    return np.array(\n",
    "        list(itertools.chain(*map(lambda i: [output[i]] * weights[i], range(len(weights))))))\n",
    "\n",
    "\n",
    "def isotonic_projection(y, g):\n",
    "    \"\"\"\n",
    "    Main function to compute a projection over cardinality based B(f).\n",
    "    This functions solved the dual problem in the dual space using the\n",
    "    PAV algorithm and then maps it back to the primal. The inputs are\n",
    "    the point y we are trying to project and a dictionary g with the\n",
    "    submodular function. g is of the form {0:0, 1:f(1),..., n:f(n)}\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(g) - 1\n",
    "    pi = np.argsort(-y)\n",
    "    C = np.array([g[i] - g[i - 1] for i in range(1, n + 1)])\n",
    "    C_ = {}\n",
    "    for i, j in enumerate(pi):\n",
    "        C_[j] = C[i]\n",
    "\n",
    "    C_ = np.array([C_[i] for i in sorted(C_.keys())])\n",
    "\n",
    "    error = C_ - y\n",
    "    error_sorted = error[pi]\n",
    "    z = poolAdjacentViolators(error_sorted)\n",
    "\n",
    "    z_ = {}\n",
    "    for i, j in enumerate(pi):\n",
    "        z_[j] = z[i]\n",
    "\n",
    "    return np.array([z_[i] for i in sorted(z_.keys())]) + y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes for submodular functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SubmodularFunction:\n",
    "    \"\"\"\n",
    "    Class to represent submodular functions\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int = 0):\n",
    "        \"\"\"\n",
    "        :param S: ground set; if you want to make the ground set [1, ..., n] set S = {} and see n\n",
    "        :param n: if you want the ground set to be the range [1, ..., n]\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def function_value(self, T: set):\n",
    "        if not T.issubset(range(self.n)):\n",
    "            raise ValueError(\"The provided set is not a subset of the ground set.\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class CardinalityDifferenceSubmodularFunction(SubmodularFunction):\n",
    "    \"\"\"\n",
    "    Class to represent a submodular function of the form f1(W) = f(W) - r(W), where r is a vector\n",
    "    and f is given\n",
    "    \"\"\"\n",
    "    def __init__(self, g, r, n: int = 0):\n",
    "        super().__init__(n)\n",
    "        # We assume that the list g is the tuple (g(1), ..., g(n)). We append g(0) = 0 to this list\n",
    "        # Check if g induces a submodular function f\n",
    "        if not self.is_cardianality_submodular([0.0] + g):\n",
    "            raise TypeError('The tuple g does not induce a cardinality based polytope.')\n",
    "\n",
    "        if len(g) != len(r) or len(g) != n:\n",
    "            print(n, len(g), len(r))\n",
    "            raise ValueError('Sizes not same.')\n",
    "\n",
    "        self.g = [0.0] + g\n",
    "        self.r = r\n",
    "\n",
    "    def function_value(self, T: set):\n",
    "        if not T.issubset(range(len(self) + 1)):\n",
    "            raise ValueError(\"The provided set is not a subset of the ground set.\")\n",
    "\n",
    "        return self.g[len(T)]  # - r_T\n",
    "\n",
    "    @staticmethod\n",
    "    def is_cardianality_submodular(g):\n",
    "        \"\"\"\n",
    "        Checks if the cardinality function g induces submodular f\n",
    "        :param g: cardinality function g on {0, 1, ..., n}\n",
    "        :return: True if f is submodular, False otherwise\n",
    "        \"\"\"\n",
    "        n = len(g) - 1\n",
    "\n",
    "        # Check if g is monotonic nonincreasing\n",
    "        for i in range(n):\n",
    "            if g[i + 1] < g[i]:\n",
    "                logging.debug('Nonmonotonic: i = ' + str(i) + ', g[i] = ' + str(g[i]) +\n",
    "                              ', g[i + 1] = ' + str(g[i + 1]))\n",
    "                return False\n",
    "\n",
    "        # Check if g is concave\n",
    "        for i in range(n - 1):\n",
    "            if g[i] + g[i + 2] > 2 * g[i + 1] + minimum_decimal_difference:\n",
    "                logging.debug('Not concave: i = ' + str(i) + ', g[i] = ' + str(g[i]) +\n",
    "                              ', g[i + 1] = ' + str(g[i + 1]) + ', g[i + 2] = ' + str(g[i + 2]))\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "class CardinalitySubmodularFunction(CardinalityDifferenceSubmodularFunction):\n",
    "    \"\"\"\n",
    "    Class for cardinality-based submodular functions\n",
    "    \"\"\"\n",
    "    def __init__(self, g, n):\n",
    "        r = [0.0] * n\n",
    "        super().__init__(g, r, n)\n",
    "\n",
    "\n",
    "class PermutahedronSubmodularFunction(CardinalitySubmodularFunction):\n",
    "    def __init__(self, n: int = 1):\n",
    "        g = [float(n)]\n",
    "        for i in range(1, n):\n",
    "            g.append(float(g[-1] + n - i))\n",
    "        super().__init__(g, n)\n",
    "\n",
    "\n",
    "class SubmodularPolytope:\n",
    "    \"\"\"\n",
    "    Class to represent submodular polytopes\n",
    "    \"\"\"\n",
    "    def __init__(self, f: SubmodularFunction):\n",
    "        self.f = f\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.f)\n",
    "\n",
    "    def is_feasible(self, x):\n",
    "        pass\n",
    "\n",
    "    def linear_optimization_over_base(self, c):\n",
    "        \"\"\"\n",
    "        Returns max (c^T x) and argmin (c^T x) for x in B(f)\n",
    "        :param c: Vector of length |E|\n",
    "        :return: max c^T x for x in B(f)\n",
    "        \"\"\"\n",
    "        d, mapping = sort(c, reverse=True)  # Sort in revese order for greedy algorithm\n",
    "        inverse = invert(mapping)           # Inverse permutation\n",
    "\n",
    "        x = [0.0] * len(self)  # This will be the argmax\n",
    "        # Greedy algorithm\n",
    "        for i in range(len(self)):\n",
    "            S_up = map_set(set(range(i + 1)), inverse)\n",
    "            S_down = map_set(set(range(i)), inverse)\n",
    "            x[i] = self.f.function_value(S_up) - self.f.function_value(S_down)\n",
    "\n",
    "        opt = sum([x[i] * d[i] for i in range(len(self))])  # Opt value\n",
    "        invert_x = permute(x, inverse)  # Restore the original order for x\n",
    "\n",
    "        return opt, invert_x\n",
    "\n",
    "    @staticmethod\n",
    "    def check_chain(T):\n",
    "        \"\"\"\n",
    "        Checks if a given list of sets forms a chain\n",
    "        :param T: List of sets\n",
    "        :return: Boolean\n",
    "        \"\"\"\n",
    "        flag = True\n",
    "        for i in range(len(T) - 1):\n",
    "            if not T[i].issubset(T[i + 1]):\n",
    "                flag = False\n",
    "\n",
    "        return flag\n",
    "\n",
    "    def linear_optimization_tight_sets(self, c, T):\n",
    "        \"\"\"\n",
    "        Linear optimization over B(f) with additional constraints. Every set in T should also be\n",
    "        tight. Returns max (c^Tx) and argmin (c^T x) for x in B(f), with the additional\n",
    "        constraints that x(U) = f(U) for all U in T.\n",
    "        :param c: cost vector\n",
    "        :param T: set of tight sets. Assumed to be a chain for now, and T is assumed to be\n",
    "        increasing. T[0] is assumed to be the emptyset set({}) and T[-1] is assumed to be the\n",
    "        ground set\n",
    "        :return: max c^T x under the constraints\n",
    "        \"\"\"\n",
    "        # print('T = ', T)\n",
    "        if T[-1] is not frozenset(range(len(self))):\n",
    "            T.append(frozenset(range(len(self))))\n",
    "\n",
    "        if not self.check_chain(T):\n",
    "            raise ValueError('The given chain of sets does not form a chain.')\n",
    "\n",
    "        permutation = {}\n",
    "        count = 0\n",
    "        for j in range(1, len(T)):\n",
    "            U = T[j]\n",
    "            D = U.difference(T[j - 1])\n",
    "            for u in D:\n",
    "                permutation[u] = count\n",
    "                count = count + 1\n",
    "\n",
    "        inverse_permutation = invert(permutation)\n",
    "        c1 = permute(c, permutation)\n",
    "        x = []\n",
    "        l = 0\n",
    "        opt = 0\n",
    "\n",
    "        # print(permutation, inverse_permutation)\n",
    "\n",
    "        for j in range(1, len(T)):\n",
    "            U = T[j]\n",
    "            y = []\n",
    "            D = U.difference(T[j - 1])\n",
    "            m = len(D)\n",
    "            d, mapping = sort(c1[l: l + m], reverse=True)\n",
    "            inverse = invert(mapping)\n",
    "            for i in range(m):\n",
    "                D_up_inverse = map_set(set(range(i + 1)), inverse)\n",
    "                D_up_inverse = set([a + l for a in list(range(i + 1))])\n",
    "\n",
    "                D_down_inverse = map_set(set(range(i)), inverse)\n",
    "                D_down_inverse = set([a + l for a in list(range(i))])\n",
    "\n",
    "                S_up = T[j - 1].union(map_set(D_up_inverse, inverse_permutation))\n",
    "                S_down = T[j - 1].union(map_set(D_down_inverse, inverse_permutation))\n",
    "\n",
    "                y.append(self.f.function_value(S_up) - self.f.function_value(S_down))\n",
    "                opt = opt + d[i] * y[-1]\n",
    "            y = permute(y, inverse)\n",
    "            x = x + y\n",
    "            l = l + m\n",
    "\n",
    "        z = permute(x, invert(permutation))\n",
    "        return opt, z\n",
    "\n",
    "    def affine_minimizer(self, S):\n",
    "        n = len(self)\n",
    "        B = np.column_stack(S)\n",
    "        C = np.transpose(B)\n",
    "        D = np.linalg.inv(np.matmul(C, B))\n",
    "        o = np.ones(n)\n",
    "        alpha = (np.matmul(D, o)) / (np.matmul(o, np.matmul(D, o)))\n",
    "        y = np.matmul(B, alpha)\n",
    "        return y, alpha\n",
    "\n",
    "    def minimum_norm_point(self, eps: float):\n",
    "        def get_base_vertex():\n",
    "            return [self.f.function_value(set(range(i + 1))) - self.f.function_value(set(range(i)))\n",
    "                    for i in range(n)]\n",
    "\n",
    "        def nonnegative_coordinates(y):\n",
    "            C = {}\n",
    "            for i in range(len(y)):\n",
    "                if y[i] < 0:\n",
    "                    C.update({i: y[i]})\n",
    "\n",
    "            return C\n",
    "\n",
    "        eps = abs(eps)\n",
    "        x = get_base_vertex()\n",
    "        S = [x]  # Set S in the algorithm\n",
    "        L = [1]  # Coefficients lambda_i\n",
    "        s = 1  # |S|\n",
    "        while True:\n",
    "            _, q = self.linear_optimization_over_base(x)\n",
    "            if np.linalg.norm(x) * np.linalg.norm(x) <= np.matmul(x, q) + eps * eps:\n",
    "                break\n",
    "\n",
    "            S = S + [q]\n",
    "            L.append(0.0)\n",
    "\n",
    "            while True:\n",
    "                y, alpha = self.affine_minimizer(S)\n",
    "                C = nonnegative_coordinates(alpha)\n",
    "                if len(C) == 0:\n",
    "                    break\n",
    "\n",
    "                theta = min([L[k] / (L[k] - alpha[k]) for k in C])\n",
    "                x = theta * y + (1 - theta) * x\n",
    "                L = theta * y + (1 - theta) * L\n",
    "\n",
    "            x = y\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CardinalityPolytope(SubmodularPolytope):\n",
    "    \"\"\"\n",
    "    Class for cardinality based polytopes. Let N be the ground set of size n. Then,\n",
    "    f is a submodular function on the power set of N, given by f(A) = g(|A|) for each subset A of\n",
    "    N. g is called the cardinality function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f: CardinalitySubmodularFunction):\n",
    "        super().__init__(f)\n",
    "        self.f = f\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: size of the ground set S\n",
    "        \"\"\"\n",
    "        return len(self.f)\n",
    "\n",
    "    def is_feasible(self, x):\n",
    "        \"\"\"\n",
    "        Checks if point x is in P(f)\n",
    "        :param x: point in space\n",
    "        :return: True if x is in P(f), False, otherwise\n",
    "        \"\"\"\n",
    "        # Descending sort\n",
    "        x.sort(reverse=True)\n",
    "\n",
    "        n = len(x)\n",
    "        # Check if dimensions match:\n",
    "        if n != len(self):\n",
    "            raise ValueError('The dimension ' + str(n) + 'of the point does not match the '\n",
    "                                                         'dimension ' + str(\n",
    "                len(self)) + ' of the ground set.')\n",
    "\n",
    "        # Check if x[0] + x[1] + ... + x[i - 1] <= g[i]\n",
    "        prefix_sum_x = self.prefix_sum(x)\n",
    "        for i in range(n):\n",
    "            if prefix_sum_x[i] > self.f.g[i + 1]:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def is_feasible_in_base(self, x):\n",
    "        \"\"\"\n",
    "        Checks if x in is B(f)\n",
    "        :param x: point in space\n",
    "        :return: True if x is in B(f), False otherwise\n",
    "        \"\"\"\n",
    "        return True if sum(x) == self.f.g[-1] and self.is_feasible(x) else False\n",
    "\n",
    "    @staticmethod\n",
    "    def prefix_sum(x):\n",
    "        \"\"\"\n",
    "        :param x: Point in space\n",
    "        :return: prefix sum of x\n",
    "        \"\"\"\n",
    "        prefix_sum = [x[0]]\n",
    "        for i in range(1, len(x)):\n",
    "            prefix_sum.append(round(prefix_sum[i - 1] + x[i], high_decimal_accuracy))\n",
    "\n",
    "        return prefix_sum\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(x: float, y: float):\n",
    "        return abs(x - y)\n",
    "\n",
    "\n",
    "class Permutahedron(CardinalityPolytope):\n",
    "    def __init__(self, f: PermutahedronSubmodularFunction):\n",
    "        super().__init__(f)\n",
    "\n",
    "\n",
    "def tight_set_rounded_solution(C: CardinalityPolytope, H, y):\n",
    "    \"\"\"\n",
    "    T is assumed to contain the empty set and the ground set, and is assumed to be a chain.\n",
    "    :param C:\n",
    "    :param T:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(C)\n",
    "    x = np.zeros(n)\n",
    "\n",
    "    for j in range(1, len(H)):\n",
    "        F = H[j].difference(H[j - 1])\n",
    "        y_F = sum([y[k] for k in F])\n",
    "        alpha = (C.f.function_value(H[j]) - C.f.function_value(H[j - 1]) - y_F)/len(F)\n",
    "        for i in F:\n",
    "            x[i] = alpha + y[i]\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def cut_rounding(C: CardinalityPolytope, H, y, S):\n",
    "    \"\"\"\n",
    "    Function for tight-set based round algorithm\n",
    "    :param C: Cardinality-based polytope\n",
    "    :param H:\n",
    "    :param y:\n",
    "    :param S:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    H.sort(key=len)\n",
    "\n",
    "    x = tight_set_rounded_solution(C, H, y)\n",
    "    is_convex_combination = active_set_oracle(S, x)\n",
    "\n",
    "    if is_convex_combination:\n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError('Cannot round, x not feasible.')\n",
    "\n",
    "\n",
    "def sample_vertex_from_convex_combination(S):\n",
    "    vertices = list(S.keys())\n",
    "    s = len(S)\n",
    "    distribution = np.array(list(S.values()))\n",
    "    sum_distribution = sum(distribution)\n",
    "    distribution = (1 / sum_distribution) * distribution\n",
    "    v = np.random.choice(s, p=distribution)\n",
    "    return np.array(vertices[v])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFW based projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def projection_on_permutahedron_using_afw_euclidean(n, y, epsilon, lmo, S=None, x=None):\n",
    "    \"\"\"\n",
    "    :param n: |E|\n",
    "    :param y: Point to project\n",
    "    :param epsilon: Error\n",
    "    :param S: Ative set dict\n",
    "    :param x: Intial iterate\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    h = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "    grad_h = lambda x: np.power(x - y, 1)\n",
    "    h_tol, time_tol = -1, np.inf\n",
    "\n",
    "    if x is None:\n",
    "        w = generate_random_permutation(n)\n",
    "        x = w\n",
    "        S = {tuple(w): 1}\n",
    "\n",
    "    A = AFW(np.array(x), S, lmo, epsilon, h, grad_h, h_tol, time_tol)\n",
    "    # print(A)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mirror descent variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vanilla_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta):\n",
    "    total_time = 0.0\n",
    "    fw_iterations = []\n",
    "    step_regret = []\n",
    "    time_steps = []\n",
    "    opt, alg = 0.0, 0.0\n",
    "\n",
    "    def lmo(c):\n",
    "        _, v = P.linear_optimization_over_base(c)\n",
    "        return tuple(v)\n",
    "\n",
    "    S = {x_0: 1}\n",
    "    x = x_0\n",
    "\n",
    "    for t in range(T):\n",
    "        logging.warning('Iteration ' + str(t))\n",
    "        # sigma = sample_vertex_from_convex_combination(S)\n",
    "        sigma = x\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(l, sigma)\n",
    "        alg = loss\n",
    "\n",
    "        sol, x_star = P.linear_optimization_over_base(list(-l))\n",
    "\n",
    "        opt = np.dot(l, x_star)\n",
    "        step_regret.append(alg - opt)\n",
    "\n",
    "        y = x - eta * l\n",
    "\n",
    "        x, _, fw_time, fw_iter, _, S = \\\n",
    "            projection_on_permutahedron_using_afw_euclidean(n, y, epsilon, lmo, {x_0: 1}, x_0)\n",
    "\n",
    "        time_steps.append(sum(fw_time))\n",
    "\n",
    "        fw_iterations.append(fw_iter)\n",
    "        total_time = total_time + sum(fw_time)\n",
    "\n",
    "    return time_steps, total_time, fw_iterations, step_regret\n",
    "\n",
    "\n",
    "def isotonic_projection_mirror_descent(n, P, T, loss_vectors_list, x_0, eta):\n",
    "    total_time = 0.0\n",
    "    time_steps = []\n",
    "    step_regret = []\n",
    "    opt, alg = 0.0, 0.0\n",
    "\n",
    "    def lmo(c):\n",
    "        _, v = P.linear_optimization_over_base(c)\n",
    "        return tuple(v)\n",
    "\n",
    "    x = x_0\n",
    "    for t in range(T):\n",
    "        t1 = time.time()\n",
    "        logging.warning('Iteration ' + str(t))\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        sol, x_star = P.linear_optimization_over_base(list(-l))\n",
    "\n",
    "        opt = np.dot(l, x_star)\n",
    "        alg = np.dot(l, x)\n",
    "        step_regret.append(alg - opt)\n",
    "\n",
    "        y = x - eta * l\n",
    "        g = {i: P.f.g[i] for i in range(n + 1)}\n",
    "        x = isotonic_projection(y, g)\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        total_time = total_time + (t2 - t1)\n",
    "        time_steps.append(t2 - t1)\n",
    "\n",
    "    return time_steps, total_time, step_regret\n",
    "\n",
    "\n",
    "def active_set_optimized_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta):\n",
    "    total_time = 0.0\n",
    "    fw_iterations = []\n",
    "    time_steps = []\n",
    "    opt, alg = 0.0, 0.0\n",
    "    step_regret = []\n",
    "\n",
    "    def lmo(c):\n",
    "        _, v = P.linear_optimization_over_base(c)\n",
    "        return tuple(v)\n",
    "\n",
    "    S = {x_0: 1}\n",
    "    x = x_0\n",
    "    for t in range(T):\n",
    "        logging.warning('Iteration ' + str(t))\n",
    "        # sigma = sample_vertex_from_convex_combination(S)\n",
    "        sigma = x\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(l, sigma)\n",
    "        alg = loss\n",
    "\n",
    "        sol, x_star = P.linear_optimization_over_base(list(-l))\n",
    "        opt = np.dot(l, x_star)\n",
    "        step_regret.append(alg - opt)\n",
    "\n",
    "        y = x - eta * l\n",
    "        if t > 0:\n",
    "            x, S = convex_hull_correction2(S, y)\n",
    "\n",
    "        x, _, fw_time, fw_iter, _, S = \\\n",
    "            projection_on_permutahedron_using_afw_euclidean(n, y, epsilon, lmo, S, x)\n",
    "\n",
    "        time_steps.append(sum(fw_time))\n",
    "\n",
    "        fw_iterations.append(fw_iter)\n",
    "        total_time = total_time + sum(fw_time)\n",
    "\n",
    "    return time_steps, total_time, fw_iterations, step_regret\n",
    "\n",
    "\n",
    "def cut_optimized_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta):\n",
    "    def get_chain(tight_sets):\n",
    "        if frozenset(set(range(n))) not in tight_sets:\n",
    "            tight_sets.add(frozenset(range(n)))\n",
    "        if frozenset(set()) not in tight_sets:\n",
    "            tight_sets.add(frozenset(set()))\n",
    "\n",
    "        tight_sets = list(tight_sets)\n",
    "        tight_sets.sort(key=len)\n",
    "\n",
    "        for i in range(1, len(tight_sets)):\n",
    "            if not tight_sets[i - 1].issubset(tight_sets[i]):\n",
    "                raise ValueError('Tight sets list is bad :(')\n",
    "\n",
    "        if tight_sets[-1] != frozenset(range(n)):\n",
    "            tight_sets.append(frozenset(range(n)))\n",
    "\n",
    "        return tight_sets\n",
    "\n",
    "    def infer_tight_sets_from_close_point(d, tight_sets1):\n",
    "        \"\"\"\n",
    "        Infers tights sets for tilde(y) from tight sets for y\n",
    "        :param d: distance d(y, tilde(y))\n",
    "        :param tight_sets1: tight_sets of point y, along with their c[j + 1] - c[j] values,\n",
    "        sorted by their c[j + 1] - c[j] values\n",
    "        :return: inferred tight sets for tilde(y), list\n",
    "        \"\"\"\n",
    "        inferred_tight_sets = set()\n",
    "\n",
    "        for t in range(len(tight_sets1)):\n",
    "            a = tight_sets1[t]\n",
    "            if 4 * d < a[0]:\n",
    "                inferred_tight_sets.add(a[1])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return inferred_tight_sets\n",
    "\n",
    "    total_time = 0.0\n",
    "    fw_iterations = []\n",
    "    points_list = []\n",
    "    tight_sets_list = []\n",
    "    opt, alg = 0.0, 0.0\n",
    "    time_steps = []\n",
    "    step_regret = []\n",
    "\n",
    "    def lmo(c):\n",
    "        _, v = P.linear_optimization_over_base(c)\n",
    "        return tuple(v)\n",
    "\n",
    "    S = {x_0: 1}\n",
    "    x = x_0\n",
    "    for t in range(T):\n",
    "        logging.warning('Iteration ' + str(t))\n",
    "        # sigma = sample_vertex_from_convex_combination(S)\n",
    "        sigma = x\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(l, sigma)\n",
    "        alg = loss\n",
    "\n",
    "        sol, x_star = P.linear_optimization_over_base(list(-l))\n",
    "        opt = np.dot(l, x_star)\n",
    "\n",
    "        step_regret.append(alg - opt)\n",
    "\n",
    "        y = x - eta * l\n",
    "        points_list.append(y)\n",
    "\n",
    "        tight_sets = set()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for i in range(len(points_list) - 1):\n",
    "            d = np.linalg.norm(y - points_list[i])\n",
    "            tight_sets.union(infer_tight_sets_from_close_point(d, tight_sets_list[i]))\n",
    "        t2 = time.time()\n",
    "\n",
    "        chain_of_tight_sets = set(get_chain(tight_sets))\n",
    "\n",
    "        def lmo(c):\n",
    "            _, v = P.linear_optimization_tight_sets(c, chain_of_tight_sets)\n",
    "            return v\n",
    "\n",
    "        h = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_h = lambda x: np.power(x - y, 1)\n",
    "        h_tol, time_tol = -1, np.inf\n",
    "\n",
    "        x, _, fw_time, fw_iter, _, S, _ = \\\n",
    "            adaptive_AFW_cardinality_polytope(x, {tuple(x): 1}, P, epsilon, h, grad_h, h_tol,\n",
    "                                              time_tol,\n",
    "                                              chain_of_tight_sets, y)\n",
    "\n",
    "        time_steps.append(sum(fw_time) + t2 - t1)\n",
    "\n",
    "        tight_sets_list.append(determine_tight_sets(y, x))\n",
    "        fw_iterations.append(fw_iter)\n",
    "        total_time = total_time + sum(fw_time)\n",
    "\n",
    "    return time_steps, total_time, fw_iterations, step_regret\n",
    "\n",
    "\n",
    "def doubly_optimized_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta):\n",
    "    def get_chain(tight_sets):\n",
    "        if frozenset(set(range(n))) not in tight_sets:\n",
    "            tight_sets.add(frozenset(range(n)))\n",
    "        if frozenset(set()) not in tight_sets:\n",
    "            tight_sets.add(frozenset(set()))\n",
    "\n",
    "        tight_sets = list(tight_sets)\n",
    "        tight_sets.sort(key=len)\n",
    "\n",
    "        for i in range(1, len(tight_sets)):\n",
    "            if not tight_sets[i - 1].issubset(tight_sets[i]):\n",
    "                raise ValueError('Tight sets list is bad :(')\n",
    "\n",
    "        if tight_sets[-1] != frozenset(range(n)):\n",
    "            tight_sets.append(frozenset(range(n)))\n",
    "\n",
    "        return tight_sets\n",
    "\n",
    "    def infer_tight_sets_from_close_point(d, tight_sets1):\n",
    "        \"\"\"\n",
    "        Infers tights sets for tilde(y) from tight sets for y\n",
    "        :param d: distance d(y, tilde(y))\n",
    "        :param tight_sets1: tight_sets of point y, along with their c[j + 1] - c[j] values,\n",
    "        sorted by their c[j + 1] - c[j] values\n",
    "        :return: inferred tight sets for tilde(y), list\n",
    "        \"\"\"\n",
    "        inferred_tight_sets = set()\n",
    "\n",
    "        for t in range(len(tight_sets1)):\n",
    "            a = tight_sets1[t]\n",
    "            if 4 * d < a[0]:\n",
    "                inferred_tight_sets.add(a[1])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return inferred_tight_sets\n",
    "\n",
    "    total_time = 0.0\n",
    "    fw_iterations = []\n",
    "    points_list = []\n",
    "    tight_sets_list = []\n",
    "    opt, alg = 0.0, 0.0\n",
    "    time_steps = []\n",
    "    step_regret = []\n",
    "\n",
    "    def lmo(c):\n",
    "        _, v = P.linear_optimization_over_base(c)\n",
    "        return tuple(v)\n",
    "\n",
    "    S = {x_0: 1}\n",
    "    x = x_0\n",
    "    for t in range(T):\n",
    "        logging.warning('Iteration ' + str(t))\n",
    "\n",
    "        # sigma = sample_vertex_from_convex_combination(S)\n",
    "        sigma = x\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(sigma, l)\n",
    "        alg = loss\n",
    "\n",
    "        sol, x_star = P.linear_optimization_over_base(list(-l))\n",
    "        opt = np.dot(l, x_star)\n",
    "        step_regret.append(alg - opt)\n",
    "\n",
    "        y = x - eta * l\n",
    "        points_list.append(y)\n",
    "\n",
    "        tight_sets = set()\n",
    "        t1 = time.time()\n",
    "        for i in range(len(points_list) - 1):\n",
    "            d = np.linalg.norm(y - points_list[i])\n",
    "            tight_sets.union(infer_tight_sets_from_close_point(d, tight_sets_list[i]))\n",
    "        chain_of_tight_sets = set(get_chain(tight_sets))\n",
    "        t2= time.time()\n",
    "\n",
    "        def lmo(c):\n",
    "            _, v = P.linear_optimization_tight_sets(c, chain_of_tight_sets)\n",
    "            return v\n",
    "\n",
    "        h = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_h = lambda x: np.power(x - y, 1)\n",
    "        h_tol, time_tol = -1, np.inf\n",
    "\n",
    "        x, S = convex_hull_correction2(S, y)\n",
    "        x, _, fw_time, fw_iter, _, S, _ = \\\n",
    "            adaptive_AFW_cardinality_polytope(x, S, P, epsilon, h, grad_h, h_tol,\n",
    "                                              time_tol,\n",
    "                                              chain_of_tight_sets, y)\n",
    "\n",
    "        time_steps.append(sum(fw_time) + t2 - t1)\n",
    "\n",
    "        tight_sets_list.append(determine_tight_sets(y, x))\n",
    "        fw_iterations.append(fw_iter)\n",
    "        total_time = total_time + sum(fw_time)\n",
    "\n",
    "    return time_steps, total_time, fw_iterations, step_regret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OFW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def online_FW(x, lmo, T, loss_vectors_list, G=None):\n",
    "    # record primal gap, function value, and time every iteration\n",
    "    time = []\n",
    "    grad_list = [np.zeros(len(x))]\n",
    "\n",
    "    # initialize starting point and active set\n",
    "    t = 0\n",
    "    x_t = [x]\n",
    "    v_t = {}\n",
    "    loss = []\n",
    "\n",
    "    # define blocksizes and random sampling parameters\n",
    "    k = int(np.ceil(T ** (1 / 3)))\n",
    "\n",
    "    if G:\n",
    "        delta = 2 / (G * len(x) ** 0.5 * k ** 2)\n",
    "    else:\n",
    "        delta = 2 / (len(x) ** 1.5 * k ** 2)\n",
    "\n",
    "    while t < T:\n",
    "\n",
    "        start = datetime.datetime.now()\n",
    "\n",
    "        if t % k != 0:\n",
    "\n",
    "            # play x_{t-1}, i.e. dont do anything\n",
    "            x_t.append(x_t[-1])\n",
    "\n",
    "            # observe gradient/loss\n",
    "            grad = loss_vectors_list[t]\n",
    "            grad_list.append(grad)\n",
    "\n",
    "            # compute loss\n",
    "            loss.append(np.dot(x_t[-1], grad))\n",
    "\n",
    "        else:\n",
    "            v = []\n",
    "            for i in range(k):\n",
    "                v_ = np.random.normal(0, 1, n)\n",
    "                v.append(v_ / np.linalg.norm(v_))\n",
    "            v = np.array(v)\n",
    "            grad_sum = np.sum(np.array(grad_list), axis=0)\n",
    "            x = np.array([lmo(grad_sum + v[j] / delta) for j in range(k)])\n",
    "\n",
    "            # play average of x\n",
    "            x_t.append(np.mean(x, axis=0))\n",
    "\n",
    "            # observe gradient/loss\n",
    "            grad = loss_vectors_list[t]\n",
    "            grad_list.append(grad)\n",
    "\n",
    "            # compute loss\n",
    "            loss.append(np.dot(x_t[-1], grad))\n",
    "\n",
    "        end = datetime.datetime.now()\n",
    "        time.append((end - start).total_seconds())\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return x_t, time, loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Starting vanilla OMD\n",
      "WARNING:root:Iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  15 T =  500 epsilon =  0.0002962962962962963 a =  4 b =  4\n",
      "Run  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Iteration 1\n",
      "WARNING:root:Iteration 2\n",
      "WARNING:root:Iteration 3\n",
      "WARNING:root:Iteration 4\n",
      "WARNING:root:Iteration 5\n",
      "WARNING:root:Iteration 6\n",
      "WARNING:root:Iteration 7\n",
      "WARNING:root:Iteration 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-26-237d048de681>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     81\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Run '\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m     \u001B[0mt1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt6\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT6\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr6\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 83\u001B[1;33m         \u001B[0monline_mirror_descent_permutahedron\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mP\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0mtimes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mT1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT6\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-26-237d048de681>\u001B[0m in \u001B[0;36monline_mirror_descent_permutahedron\u001B[1;34m(P, T, epsilon, seed, a, b)\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwarning\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Starting vanilla OMD'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[0mtime_steps_vanilla\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtotal_time_vanilla\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfw_iterations_vanilla\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mregret_vanilla\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m         \u001B[0mvanilla_mirror_descent\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mP\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss_vectors_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m     \u001B[1;31m# Active set optimized FW\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-24-45a6d9b0fbf2>\u001B[0m in \u001B[0;36mvanilla_mirror_descent\u001B[1;34m(n, epsilon, P, T, loss_vectors_list, x_0, eta)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfw_time\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfw_iter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mS\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m             \u001B[0mprojection_on_permutahedron_using_afw_euclidean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlmo\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mx_0\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[0mtime_steps\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfw_time\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-23-91bafe724269>\u001B[0m in \u001B[0;36mprojection_on_permutahedron_using_afw_euclidean\u001B[1;34m(n, y, epsilon, lmo, S, x)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[0mS\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m     \u001B[0mA\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAFW\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlmo\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepsilon\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_h\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh_tol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtime_tol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m     \u001B[1;31m# print(A)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mA\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-20-67b31a6dd9d4>\u001B[0m in \u001B[0;36mAFW\u001B[1;34m(x, S, lmo, epsilon, func, grad_f, f_tol, time_tol)\u001B[0m\n\u001B[0;32m    172\u001B[0m             \u001B[0mAway\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    173\u001B[0m         \u001B[1;31m# Update next iterate by doing a feasible line-search\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 174\u001B[1;33m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mline_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma_max\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    175\u001B[0m         \u001B[1;31m# x, gamma = segment_search(func, grad_f, x, x + gamma_max *d)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    176\u001B[0m         \u001B[1;31m# update active set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-20-67b31a6dd9d4>\u001B[0m in \u001B[0;36mline_search\u001B[1;34m(x, d, gamma_max, func)\u001B[0m\n\u001B[0;32m     81\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 83\u001B[1;33m     \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mminimize_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbounds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma_max\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'bounded'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0mgamma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mres\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001B[0m in \u001B[0;36mminimize_scalar\u001B[1;34m(fun, bracket, bounds, args, method, tol, options)\u001B[0m\n\u001B[0;32m    796\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdisp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    797\u001B[0m             \u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'disp'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m2\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdisp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 798\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_minimize_scalar_bounded\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbounds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    799\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mmeth\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'golden'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    800\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_minimize_scalar_golden\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbracket\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001B[0m in \u001B[0;36m_minimize_scalar_bounded\u001B[1;34m(func, bounds, args, xatol, maxiter, disp, **unknown_options)\u001B[0m\n\u001B[0;32m   1976\u001B[0m         \u001B[0msi\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msign\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrat\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mrat\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1977\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxf\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0msi\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtol1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1978\u001B[1;33m         \u001B[0mfu\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1979\u001B[0m         \u001B[0mnum\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1980\u001B[0m         \u001B[0mfmin_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnum\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfu\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-20-67b31a6dd9d4>\u001B[0m in \u001B[0;36mfun\u001B[1;34m(gamma)\u001B[0m\n\u001B[0;32m     79\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgamma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m         \u001B[0mls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mgamma\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 81\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     82\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     83\u001B[0m     \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mminimize_scalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbounds\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma_max\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'bounded'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-23-91bafe724269>\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     33\u001B[0m     \"\"\"\n\u001B[0;32m     34\u001B[0m     \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 35\u001B[1;33m     \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;36m0.5\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m     \u001B[0mgrad_h\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[0mh_tol\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtime_tol\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def online_mirror_descent_permutahedron(P: Permutahedron, T: int, epsilon: float, seed, a, b):\n",
    "    \"\"\"\n",
    "    Performs online mirror descent on a permutahedron\n",
    "    :param P: permuathedron. See submodular_polytope.py for class definition\n",
    "    :param T: number of iterations\n",
    "    :param a: number of permutations\n",
    "    :param b: swap distance between permutations\n",
    "    :return: Total regret\n",
    "    \"\"\"\n",
    "    n = len(P)\n",
    "    D = (n ** 3 - n) / 6  # Diameter of permutahedron\n",
    "    G = n  # Upper bound on norm l1 norm\n",
    "    alpha = 1  # For Euclidean projection\n",
    "    eta = (D / G) * math.sqrt((2 * alpha) / T)\n",
    "\n",
    "    b = b // 2\n",
    "    loss_vectors_list = generate_loss_functions_for_permutahedron(a, b, seed, n, T)\n",
    "    x_0 = tuple(generate_random_permutation(n))\n",
    "\n",
    "    def lmo(c):\n",
    "        _, v = P.linear_optimization_over_base(-c)\n",
    "        return v\n",
    "\n",
    "    opt_values = []\n",
    "    for t in range(T):\n",
    "        x_star = lmo(loss_vectors_list[t])\n",
    "        opt_values.append(np.dot(x_star, loss_vectors_list[t]))\n",
    "\n",
    "    # Vanilla FW\n",
    "    logging.warning('Starting vanilla OMD')\n",
    "    time_steps_vanilla, total_time_vanilla, fw_iterations_vanilla, regret_vanilla = \\\n",
    "        vanilla_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta)\n",
    "\n",
    "    # Active set optimized FW\n",
    "    logging.warning('Starting active set optimized OMD')\n",
    "    time_steps_active_set_optimized, total_time_active_set_optimized, fw_iterations_active_set_optimized, regret_active_set_optimized = \\\n",
    "        active_set_optimized_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta)\n",
    "\n",
    "    # Cut optimized FW\n",
    "    logging.warning('Starting cut optimized OMD')\n",
    "    time_steps_cut_optimized, total_time_cut_optimized, fw_iterations_cut_optimized, regret_cut_optimized = \\\n",
    "        cut_optimized_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta)\n",
    "\n",
    "    # Doubly optimized FW\n",
    "    logging.warning('Starting doubly optimized OMD')\n",
    "    time_steps_doubly_optimized, total_time_doubly_optimized, fw_iterations_doubly_optimized, regret_doubly_optimized\\\n",
    "        = doubly_optimized_mirror_descent(n, epsilon, P, T, loss_vectors_list, x_0, eta)\n",
    "\n",
    "    # Isotonic projection\n",
    "    logging.warning('Starting isotonic projection OMD')\n",
    "    time_steps_isotonic, total_time_isotonic, regret_isotonic = \\\n",
    "        isotonic_projection_mirror_descent(n, P, T, loss_vectors_list, x_0, eta)\n",
    "\n",
    "    # Online FW\n",
    "    logging.warning('Starting Online FW')\n",
    "    iterates_ofw, time_steps_ofw, loss_ofw = online_FW(x_0, lmo, T, loss_vectors_list)\n",
    "    total_time_ofw = sum(time_steps_ofw)\n",
    "    regret_ofw = loss_ofw - np.array(opt_values)\n",
    "\n",
    "    return total_time_vanilla, total_time_active_set_optimized, total_time_cut_optimized, \\\n",
    "        total_time_doubly_optimized, total_time_ofw, total_time_isotonic, \\\n",
    "        time_steps_vanilla, time_steps_active_set_optimized, time_steps_cut_optimized, \\\n",
    "        time_steps_doubly_optimized, time_steps_ofw, time_steps_isotonic, \\\n",
    "        fw_iterations_vanilla, fw_iterations_active_set_optimized, \\\n",
    "        fw_iterations_cut_optimized, fw_iterations_doubly_optimized, \\\n",
    "        regret_vanilla, regret_active_set_optimized, regret_cut_optimized, \\\n",
    "        regret_doubly_optimized, regret_ofw, regret_isotonic\n",
    "\n",
    "\n",
    "n = 50\n",
    "T = 2000\n",
    "outer = 1\n",
    "epsilon = 1 / (n ** 3)\n",
    "a, b = 6, 6\n",
    "\n",
    "print('n = ', n, 'T = ', T, 'epsilon = ', epsilon, 'a = ', a, 'b = ', b)\n",
    "\n",
    "f = PermutahedronSubmodularFunction(n)\n",
    "P = Permutahedron(f)\n",
    "for seed in range(0, outer):\n",
    "    print('Run ', seed)\n",
    "    t1, t2, t3, t4, t5, t6, T1, T2, T3, T4, T5, T6, i1, i2, i3, i4, r1, r2, r3, r4, r5, r6 =\\\n",
    "        online_mirror_descent_permutahedron(P, T, epsilon, seed, a, b)\n",
    "\n",
    "    times = pd.DataFrame(columns=[T1, T2, T3, T4, T5, T6])\n",
    "    iterates = pd.DataFrame(columns=[i1, i2, i3, i4])\n",
    "    regrets = pd.DataFrame(columns=[r1, r2, r3, r4, r5, r6])\n",
    "    times.to_csv('times_' + str(seed) + '.csv')\n",
    "    iterates.to_csv('iterates_' + str(seed) + '.csv')\n",
    "    regrets.to_csv('regrets_' + str(seed) + '.csv')\n",
    "\n",
    "    print('Iteration ' + str(seed))\n",
    "\n",
    "    print('Total times')\n",
    "    print(t1)\n",
    "    print(t2)\n",
    "    print(t3)\n",
    "    print(t4)\n",
    "    print(t5)\n",
    "    print(t6)\n",
    "\n",
    "    print('Regrets')\n",
    "    print(sum(r1))\n",
    "    print(sum(r2))\n",
    "    print(sum(r3))\n",
    "    print(sum(r4))\n",
    "    print(sum(r5))\n",
    "    print(sum(r6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}