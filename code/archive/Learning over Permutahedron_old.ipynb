{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from matplotlib.path import Path\n",
    "from matplotlib import rc\n",
    "from scipy.optimize import minimize_scalar, minimize\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import itertools \n",
    "from gurobipy import*\n",
    "from time import process_time\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "from utils import *\n",
    "from constants import *\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "\n",
    "def sort(x: List[float], reverse=False):\n",
    "    \"\"\"\n",
    "    :param x: List of numbers\n",
    "    :param reverse: Sorts in decreasing order if set to True\n",
    "    :return: Sorted list and the corresponding mapping (permutation)\n",
    "    \"\"\"\n",
    "    enum = sorted(enumerate(x), key=lambda z: z[1], reverse=reverse)\n",
    "    y = [enum[j][1] for j in range(len(enum))]\n",
    "    mapping = {enum[j][0]: j for j in range(len(enum))}\n",
    "\n",
    "    return y, mapping\n",
    "\n",
    "\n",
    "def invert(mapping: Dict[int, int]):\n",
    "    \"\"\"\n",
    "    Invert a (bijective) mapping {0, ..., n - 1} -> {0, ..., n - 1}\n",
    "    :param mapping: Original mapping\n",
    "    :return: Inverse of the original mapping\n",
    "    \"\"\"\n",
    "    return {mapping[i]: i for i in range(len(mapping))}\n",
    "\n",
    "\n",
    "def map_set(S: Set[int], mapping: Dict[int, int]):\n",
    "    \"\"\"\n",
    "    Determines the range of S under mapping\n",
    "    :param S: set of integers\n",
    "    :param mapping: mapping\n",
    "    :return: range of S under mapping as a set\n",
    "    \"\"\"\n",
    "    return set({mapping[i] for i in S})\n",
    "\n",
    "\n",
    "def permute(x: List[float], mapping: Dict[int, int]):\n",
    "    \"\"\"\n",
    "    Permutes x according to mapping\n",
    "    :param x:\n",
    "    :param mapping:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y = [0.0] * len(x)\n",
    "    for i in range(len(x)):\n",
    "        y[mapping[i]] = x[i]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "class SubmodularFunction:\n",
    "    def __init__(self, n: int = 0):\n",
    "        \"\"\"\n",
    "        :param S: ground set; if you want to make the ground set [1, ..., n] set S = {} and see n\n",
    "        :param n: if you want the ground set to be the range [1, ..., n]\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def function_value(self, T: set):\n",
    "        if not T.issubset(range(self.n)):\n",
    "            raise ValueError(\"The provided set is not a subset of the ground set.\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class CardinalityDifferenceSubmodularFunction(SubmodularFunction):\n",
    "    def __init__(self, g: List[float], r: List[float], n: int = 0):\n",
    "        super().__init__(n)\n",
    "        # We assume that the list g is the tuple (g(1), ..., g(n)). We append g(0) = 0 to this list\n",
    "        # Check if g induces a submodular function f\n",
    "        if not self.is_cardianality_submodular([0.0] + g):\n",
    "            raise TypeError('The tuple g does not induce a cardinality based polytope.')\n",
    "\n",
    "        if len(g) != len(r) or len(g) != n:\n",
    "            raise ValueError('Sizes not same.')\n",
    "\n",
    "        self.g = [0.0] + g\n",
    "        self.r = r\n",
    "\n",
    "    def function_value(self, T: set):\n",
    "        if not T.issubset(range(len(self) + 1)):\n",
    "            raise ValueError(\"The provided set is not a subset of the ground set.\")\n",
    "\n",
    "        return self.g[len(T)]  # - r_T\n",
    "\n",
    "    @staticmethod\n",
    "    def is_cardianality_submodular(g: List[float]):\n",
    "        \"\"\"\n",
    "        Checks if the cardinality function g induces submodular f\n",
    "        :param g: cardinality function g on {0, 1, ..., n}\n",
    "        :return: True if f is submodular, False otherwise\n",
    "        \"\"\"\n",
    "        n = len(g) - 1\n",
    "\n",
    "        # Check if g is monotonic nonincreasing\n",
    "        for i in range(n):\n",
    "            if g[i + 1] < g[i]:\n",
    "                logging.debug('Nonmonotonic: i = ' + str(i) + ', g[i] = ' + str(g[i]) +\n",
    "                              ', g[i + 1] = ' + str(g[i + 1]))\n",
    "                return False\n",
    "\n",
    "        # Check if g is concave\n",
    "        for i in range(n - 1):\n",
    "            if g[i] + g[i + 2] > 2 * g[i + 1] + minimum_decimal_difference:\n",
    "                logging.debug('Not concave: i = ' + str(i) + ', g[i] = ' + str(g[i]) +\n",
    "                              ', g[i + 1] = ' + str(g[i + 1]) + ', g[i + 2] = ' + str(g[i + 2]))\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "class CardinalitySubmodularFunction(CardinalityDifferenceSubmodularFunction):\n",
    "    def __init__(self, g: List[float], n):\n",
    "        r = [0.0] * n\n",
    "        super().__init__(g, r, n)\n",
    "\n",
    "\n",
    "class PermutahedronSubmodularFunction(CardinalitySubmodularFunction):\n",
    "    def __init__(self, n: int = 1):\n",
    "        g = [float(n)]\n",
    "        for i in range(1, n):\n",
    "            g.append(float(g[-1] + n - i))\n",
    "        super().__init__(g, n)\n",
    "\n",
    "\n",
    "class SubmodularPolytope:\n",
    "    def __init__(self, f: SubmodularFunction):\n",
    "        self.f = f\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.f)\n",
    "\n",
    "    def is_feasible(self, x):\n",
    "        pass\n",
    "\n",
    "    def linear_optimization_over_base(self, c: List[float]):\n",
    "        \"\"\"\n",
    "        Returns max (c^T x) and argmin (c^T x) for x in B(f)\n",
    "        :param c: Vector of length |E|\n",
    "        :return: max c^T x for x in B(f)\n",
    "        \"\"\"\n",
    "        d, mapping = sort(c, reverse=True)  # Sort in revese order for greedy algorithm\n",
    "        x = [0.0] * len(self)  # This will be the argmax\n",
    "        # Greedy algorithm\n",
    "        for i in range(len(self)):\n",
    "            x[i] = self.f.function_value(set(range(i + 1))) - self.f.function_value(set(range(i)))\n",
    "\n",
    "        opt = sum([x[i] * d[i] for i in range(len(self))])  # Opt value\n",
    "        invert_x = permute(x, invert(mapping))  # Restore the original order for x\n",
    "        invert_x = round_list(invert_x, base_decimal_accuracy)  # Round to base accuracy (5 decimal)\n",
    "\n",
    "        return opt, invert_x  # Return max, argmax c^T x\n",
    "\n",
    "    def linear_optimization_tight_sets(self, c: List[float], T: List[Set]):\n",
    "        \"\"\"\n",
    "        Linear optimization over B(f) with additional constraints. Every set in T should also be\n",
    "        tight. Returns max (c^Tx) and argmin (c^T x) for x in B(f), with the additional\n",
    "        constraints that x(U) = f(U) for all U in T.\n",
    "        :param c: cost vector\n",
    "        :param T: set of tight sets. Assumed to be a chain for now, and T is assumed to be\n",
    "        increasing. T[0] is assumed to be the emptyset set({}) and T[-1] is assumed to be the\n",
    "        ground set\n",
    "        :return: max c^T x under the constraints\n",
    "        \"\"\"\n",
    "        permutation = {}\n",
    "        count = 0\n",
    "        for j in range(1, len(T)):\n",
    "            U = T[j]\n",
    "            D = U.difference(T[j - 1])\n",
    "            for u in D:\n",
    "                permutation[u] = count\n",
    "                count = count + 1\n",
    "\n",
    "        c1 = permute(c, permutation)\n",
    "        x = []\n",
    "        l = 0\n",
    "        mappings = {}\n",
    "        opt = 0\n",
    "\n",
    "        for j in range(1, len(T)):\n",
    "            U = T[j]\n",
    "            y = []\n",
    "            D = U.difference(T[j - 1])\n",
    "            m = len(D)\n",
    "            d, mapping = sort(c1[l: l + m], reverse=True)\n",
    "            inverse_mapping = invert(mapping)\n",
    "            for i in range(m):\n",
    "                y.append(self.f.function_value(set(range(i + l + 1))) - self.f.function_value(set(\n",
    "                    range(l + i))))\n",
    "                opt = opt + d[i] * (self.f.function_value(set(range(l + i + 1))) -\n",
    "                                    self.f.function_value(set(range(l + i))))\n",
    "            y = permute(y, inverse_mapping)\n",
    "            x = x + y\n",
    "            l = l + m\n",
    "\n",
    "        z = permute(x, invert(permutation))\n",
    "        return opt, z\n",
    "\n",
    "    def affine_minimizer(self, S: List[List[float]]):\n",
    "        n = len(self)\n",
    "        B = np.column_stack(S)\n",
    "        C = np.transpose(B)\n",
    "        D = np.linalg.inv(np.matmul(C, B))\n",
    "        o = np.ones(n)\n",
    "        alpha = (np.matmul(D, o)) / (np.matmul(o, np.matmul(D, o)))\n",
    "        y = np.matmul(B, alpha)\n",
    "        return y, alpha\n",
    "\n",
    "    def minimum_norm_point(self, eps: float):\n",
    "        def get_base_vertex():\n",
    "            return [self.f.function_value(set(range(i + 1))) - self.f.function_value(set(range(i)))\n",
    "                    for i in range(n)]\n",
    "\n",
    "        def nonnegative_coordinates(y: List[float]):\n",
    "            C = {}\n",
    "            for i in range(len(y)):\n",
    "                if y[i] < 0:\n",
    "                    C.update({i: y[i]})\n",
    "\n",
    "            return C\n",
    "\n",
    "        eps = abs(eps)\n",
    "        x = get_base_vertex()\n",
    "        S = [x]  # Set S in the algorithm\n",
    "        L = [1]  # Coefficients lambda_i\n",
    "        s = 1  # |S|\n",
    "        while True:\n",
    "            _, q = self.linear_optimization_over_base(x)\n",
    "            if np.linalg.norm(x) * np.linalg.norm(x) <= np.matmul(x, q) + eps * eps:\n",
    "                break\n",
    "\n",
    "            S = S + [q]\n",
    "            L.append(0.0)\n",
    "\n",
    "            while True:\n",
    "                y, alpha = self.affine_minimizer(S)\n",
    "                C = nonnegative_coordinates(alpha)\n",
    "                if len(C) == 0:\n",
    "                    break\n",
    "\n",
    "                theta = min([L[k] / (L[k] - alpha[k]) for k in C])\n",
    "                x = theta * y + (1 - theta) * x\n",
    "                L = theta * y + (1 - theta) * L\n",
    "\n",
    "            x = y\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CardinalityPolytope(SubmodularPolytope):\n",
    "    \"\"\"\n",
    "    Class for cardinality based polytopes. Let N be the ground set of size n. Then,\n",
    "    f is a submodular function on the power set of N, given by f(A) = g(|A|) for each subset A of\n",
    "    N. g is called the cardinality function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, f: CardinalitySubmodularFunction):\n",
    "        super().__init__(f)\n",
    "        self.f = f\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        :return: size of the ground set S\n",
    "        \"\"\"\n",
    "        return len(self.f)\n",
    "\n",
    "    def is_feasible(self, x: List[float]):\n",
    "        \"\"\"\n",
    "        Checks if point x is in P(f)\n",
    "        :param x: point in space\n",
    "        :return: True if x is in P(f), False, otherwise\n",
    "        \"\"\"\n",
    "        # Descending sort\n",
    "        x.sort(reverse=True)\n",
    "\n",
    "        n = len(x)\n",
    "        # Check if dimensions match:\n",
    "        if n != len(self):\n",
    "            raise ValueError('The dimension ' + str(n) + 'of the point does not match the '\n",
    "                                                         'dimension ' + str(\n",
    "                len(self)) + ' of the ground set.')\n",
    "\n",
    "        # Check if x[0] + x[1] + ... + x[i - 1] <= g[i]\n",
    "        prefix_sum_x = self.prefix_sum(x)\n",
    "        for i in range(n):\n",
    "            if prefix_sum_x[i] > self.f.g[i + 1]:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def is_feasible_in_base(self, x: List[float]):\n",
    "        \"\"\"\n",
    "        Checks if x in is B(f)\n",
    "        :param x: point in space\n",
    "        :return: True if x is in B(f), False otherwise\n",
    "        \"\"\"\n",
    "        return True if sum(x) == self.f.g[-1] and self.is_feasible(x) else False\n",
    "\n",
    "    @staticmethod\n",
    "    def prefix_sum(x: List[float]):\n",
    "        \"\"\"\n",
    "        :param x: Point in space\n",
    "        :return: prefix sum of x\n",
    "        \"\"\"\n",
    "        prefix_sum = [x[0]]\n",
    "        for i in range(1, len(x)):\n",
    "            prefix_sum.append(round(prefix_sum[i - 1] + x[i], high_decimal_accuracy))\n",
    "\n",
    "        return prefix_sum\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(x: float, y: float):\n",
    "        return abs(x - y)\n",
    "\n",
    "\n",
    "class Permutahedron(CardinalityPolytope):\n",
    "    def __init__(self, f: PermutahedronSubmodularFunction):\n",
    "        super().__init__(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_vector(v):\n",
    "    return np.array([v[k] for k in sorted(list(v.keys()))])\n",
    "\n",
    "\n",
    "def construct_function(n,g):\n",
    "    ground_set = list(range(1,n+1))\n",
    "    discrete_concave = sorted(g,reverse =True)\n",
    "    h = {}\n",
    "    h[0] = 0\n",
    "    for i,j in enumerate(discrete_concave):\n",
    "        h[i+1] = h[i] + j\n",
    "    return h\n",
    "\n",
    "\n",
    "def submodular_function(n,g):\n",
    "    \n",
    "    func = construct_function(n,g)\n",
    "    ground = list(range(1,n+1))\n",
    "    \n",
    "    def findsubsets(s, l): \n",
    "        return list(itertools.combinations(s, l)) \n",
    "\n",
    "    subsets = []\n",
    "    for i in range(1,n+1):\n",
    "        subsets.extend(findsubsets(ground, i))\n",
    "        \n",
    "    f = {}\n",
    "    f[tuple([0])] = func[0]\n",
    "    for i in subsets:\n",
    "        f[i] = func[len(i)]\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def submodular_oracle(S,func,card):\n",
    "    if card == True:\n",
    "        return func[len(S)]\n",
    "    else:\n",
    "        return func[S]\n",
    "\n",
    "    \n",
    "def greedy_submodular(w,func,card):\n",
    "    \n",
    "    #find permuation corresponding to cost vector sorted in decreasing order\n",
    "    pi = np.argsort(-w)+1\n",
    "    \n",
    "    #s is the optimal chain of elements in ground set and x is the corresponsing optimal solution constructed by greedy\n",
    "    x = {}\n",
    "    s = {}\n",
    "    s[0] = []\n",
    "    for i,j in enumerate(pi):\n",
    "        #extend chain based on permuation above\n",
    "        s[i+1] = sorted(pi[:i+1])\n",
    "        \n",
    "        #x is then the marginal gain\n",
    "        if w[j-1] > 0:\n",
    "            x[j] = submodular_oracle(tuple(s[i+1]),func,card) - submodular_oracle(tuple(s[i]),func,card)\n",
    "        else:\n",
    "            x[j] = 0\n",
    "        \n",
    "    return sort_vector(x)\n",
    "\n",
    "\n",
    "def greedy_submodular_base(w,func,card):\n",
    "    \n",
    "    #find permuation corresponding to cost vector sorted in decreasing order\n",
    "    pi = np.argsort(-w)+1\n",
    "    \n",
    "    #s is the optimal chain of elements in ground set and x is the corresponsing optimal solution constructed by greedy\n",
    "    x = {}\n",
    "    s = {}\n",
    "    s[0] = [0]\n",
    "    for i,j in enumerate(pi):\n",
    "        #extend chain based on permuation above\n",
    "        s[i+1] = sorted(pi[:i+1])\n",
    "        \n",
    "        #x is then the marginal gain\n",
    "        x[j] = submodular_oracle(tuple(s[i+1]),func,card) - submodular_oracle(tuple(s[i]),func,card)\n",
    "        \n",
    "    return sort_vector(x)\n",
    "\n",
    "\n",
    "def greedy_submodular_chains(w,func,chains):\n",
    "    \n",
    "    #find permuation corresponding to cost vector sorted in decreasing order\n",
    "    chains_new = chains + [list(np.ones(len(w)))]\n",
    "    pi = []\n",
    "    c_old = np.zeros(len(w))\n",
    "    pi_prime = np.argsort(-w)\n",
    "    for c in chains_new:\n",
    "        c_new = np.array(c) - c_old\n",
    "        s = list(np.where(c_new == 1)[0])\n",
    "        for i in pi_prime:\n",
    "            if i in s:\n",
    "                pi.append(int(i)+1)\n",
    "        c_old = c\n",
    "                \n",
    "    #s is the optimal chain of elements in ground set and x is the corresponsing optimal solution constructed by greedy\n",
    "    x = {}\n",
    "    s = {}\n",
    "    s[0] = []\n",
    "    k = int(sum(chains[-1]))\n",
    "    for i,j in enumerate(pi):\n",
    "        #extend chain based on permuation above\n",
    "        s[i+1] = sorted(pi[:i+1])\n",
    "        \n",
    "        #x is then the marginal gain\n",
    "        if w[j-1] >= 0 or i +1 <=k :\n",
    "            x[j] = submodular_oracle(tuple(s[i+1]),func,card) - submodular_oracle(tuple(s[i]),func,card)\n",
    "        else:\n",
    "            x[j] = 0\n",
    "        \n",
    "    return sort_vector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_card(x_0,a,func):\n",
    "    n = len(x_0)\n",
    "    card = True\n",
    "\n",
    "    #check if all components of LS direction are negative since in this case result is trivial\n",
    "    if all(a <0):\n",
    "        lam = 0\n",
    "\n",
    "    #otherwise we run discrete Newtons method for LS    \n",
    "    else:\n",
    "\n",
    "        #find initial lam based on singletons in the ground set; also gives check if a is feasible direction to begin with\n",
    "        lam = min([(submodular_oracle([i+1],func,card) - x_0[i])/j for i,j in enumerate(a) if j > 0])\n",
    "        \n",
    "        #we only need to do n iterations since our polytope is cardinality based\n",
    "        for i in range(len(x_0)):\n",
    "            #try moving with magnitued lam\n",
    "            y = x_0 + lam*a\n",
    "\n",
    "            #sort y so we can check feasiblity in the base polytope\n",
    "            pi = np.argsort(-y)+1\n",
    "            \n",
    "            #find cummulative sums of sorted vector so we can check feasibility/violations\n",
    "            s = np.cumsum(sorted(y,reverse =True))\n",
    "            violations = [func[i+1] - j for i,j in enumerate(s)]\n",
    "            \n",
    "            #find maximum violation and most violated set\n",
    "            card_violated,violation_value = min(enumerate(violations), key=lambda x : x[1])\n",
    "            #card_violated = min([i+1 for i,j in enumerate(violations) if j == violation_value])\n",
    "            \n",
    "            \n",
    "            #if smallest violation is 0 (note they can't all be strictly greater than 0  because of base polytope)\n",
    "            if np.round(violation_value,4) == 0:\n",
    "                break\n",
    "                \n",
    "            #otherwise we update step size and repeat\n",
    "            else:\n",
    "                most_violated_set = pi[:card_violated+1]\n",
    "                lam = (submodular_oracle(most_violated_set,func,card) - sum([x_0[i-1] for i in most_violated_set]))\\\n",
    "                        /sum([a[i-1] for i in most_violated_set])\n",
    "                \n",
    "    #note that if the sum of a != 0, then a will not satisfy base constraint, i.e. its not a feasbile direction\n",
    "    #So if a is a feasbile direction for the polymatroid but not for the base polytope ground set V will\n",
    "    #be the most violated in one of the iterations above. Thus, since x_0 \\in B(f) we know that x(V) = f(V) \n",
    "    # and hence when updating lam the numerator will be 0 for the iteration which would then give that lam = 0\n",
    "    # this shows the correctness of the algorithm and our construction of the violation for base constraint\n",
    "    return lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicator(S,n):\n",
    "    dic = {k:0 for k in range(1,n+1)}\n",
    "    for i in S:\n",
    "        dic[i] = 1\n",
    "    return sort_vector(dic)\n",
    "\n",
    "\n",
    "def get_tight_sets(x,func):\n",
    "    tight_sets = []\n",
    "    s = np.cumsum(sorted(x,reverse =True))\n",
    "    pi = np.argsort(-x)+1\n",
    "    slack = [func[i+1] - j for i,j in enumerate(s)]\n",
    "    for i,j in enumerate(slack):\n",
    "        if np.round(j,4) > 0:\n",
    "            continue\n",
    "        else:\n",
    "            tight_sets.append(get_indicator(pi[:i+1],n))\n",
    "            \n",
    "    return tight_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line-search using golden-section rule\n",
    "def segment_search(f, grad_f, x, y, tol=1e-6, stepsize=True):\n",
    "    \n",
    "    '''\n",
    "    Minimizes f over [x, y], i.e., f(x+gamma*(y-x)) as a function of scalar gamma in [0,1]\n",
    "    '''\n",
    "    \n",
    "    # restrict segment of search to [x, y]\n",
    "    d = (y-x).copy()\n",
    "    left, right = x.copy(), y.copy()\n",
    "    \n",
    "    # if the minimum is at an endpoint\n",
    "    if np.dot(d, grad_f(x))*np.dot(d, grad_f(y)) >= 0:\n",
    "        if f(y) <= f(x):\n",
    "            return y, 1\n",
    "        else:\n",
    "            return x, 0\n",
    "    \n",
    "    # apply golden-section method to segment\n",
    "    gold = (1+np.sqrt(5))/2\n",
    "    improv = np.inf\n",
    "    while improv > tol:\n",
    "        old_left, old_right = left, right\n",
    "        new = left+(right-left)/(1+gold)\n",
    "        probe = new+(right-new)/2\n",
    "        if f(probe) <= f(new):\n",
    "            left, right = new, right\n",
    "        else:\n",
    "            left, right = left, probe\n",
    "        improv = np.linalg.norm(f(right)-f(old_right))+np.linalg.norm(f(left)-f(old_left))\n",
    "    x_min = (left+right)/2\n",
    "    \n",
    "    # compute step size gamma\n",
    "    gamma = 0\n",
    "    if stepsize == True:\n",
    "        for i in range(len(d)):\n",
    "            if d[i] != 0:\n",
    "                gamma = (x_min[i]-x[i])/d[i]\n",
    "                break\n",
    "                \n",
    "    return x_min, gamma\n",
    "\n",
    "\n",
    "#Fucntion to compute away vertex\n",
    "def away_step(grad, S):\n",
    "    costs = {}\n",
    "    \n",
    "    for k,v in S.items():\n",
    "        cost = np.dot(k,grad)\n",
    "        costs[cost] = [k,v]\n",
    "    vertex, alpha = costs[max(costs.keys())]  \n",
    "    return vertex,alpha\n",
    "\n",
    "#Function to update active set\n",
    "def update_S(S,gamma, Away, vertex):\n",
    "    \n",
    "    S = S.copy()\n",
    "    vertex = tuple(vertex)\n",
    "    \n",
    "    if not Away:\n",
    "        if vertex not in S.keys():\n",
    "            S[vertex] = gamma\n",
    "        else:\n",
    "            S[vertex] *= (1-gamma)\n",
    "            S[vertex] += gamma\n",
    "            \n",
    "        for k in S.keys():\n",
    "            if k != vertex:\n",
    "                S[k] *= (1-gamma)\n",
    "    else:\n",
    "        for k in S.keys():\n",
    "            if k != vertex:\n",
    "                S[k] *= (1+gamma)\n",
    "            else:\n",
    "                S[k] *= (1+gamma)\n",
    "                S[k] -= gamma\n",
    "    return {k:v for k,v in S.items() if np.round(v,6) > 0}\n",
    "\n",
    "\n",
    "def line_search(x, d, gamma_max,func):\n",
    "\n",
    "    def fun(gamma):\n",
    "        ls = x + gamma*d\n",
    "        return func(ls)\n",
    "\n",
    "\n",
    "    res = minimize_scalar(fun, bounds=(0, gamma_max), method='bounded')\n",
    "\n",
    "    gamma = res.x\n",
    "    ls = x + gamma*d        \n",
    "    return ls, gamma\n",
    "\n",
    "\n",
    "#AFW Algorithm\n",
    "def AFW(x, S, lmo, epsilon, func, grad_f, f_tol, time_tol):\n",
    "    \n",
    "    #record primal gap, function value, and time every iteration\n",
    "    now=datetime.datetime.now()\n",
    "    primal_gap = []\n",
    "    function_value=[func(x)]\n",
    "    time = [0]\n",
    "    f_improv = np.inf\n",
    "\n",
    "    #initialize starting point and active set\n",
    "    t = 0    \n",
    "\n",
    "    while f_improv > f_tol and time[-1] < time_tol:\n",
    "        # print('here!')\n",
    "        \n",
    "        start = process_time()\n",
    "        \n",
    "        #compute gradient\n",
    "        grad = grad_f(x)\n",
    "\n",
    "        #solve linear subproblem and compute FW direction\n",
    "        v = lmo(-grad)\n",
    "        # print(v)\n",
    "        d_FW = tuple(np.array(v) - np.array(x))\n",
    "\n",
    "        #If primal gap is small enough - terminate\n",
    "        if np.dot(-grad,d_FW) <= epsilon:\n",
    "            # print(epsilon, grad, d_FW, np.dot(-grad, d_FW))\n",
    "            # print('dot too small :(')\n",
    "            break\n",
    "        else:\n",
    "            #update convergence data\n",
    "            primal_gap.append(np.dot(-grad,d_FW))\n",
    "\n",
    "        #Compute away vertex and direction\n",
    "        a,alpha_a = away_step(grad, S)\n",
    "        d_A = tuple(np.array(x) - np.array(a))\n",
    "\n",
    "        #Check if FW gap is greater than away gap\n",
    "        if np.dot(-grad,d_FW) >= np.dot(-grad,d_A):\n",
    "            #choose FW direction\n",
    "            d = d_FW\n",
    "            vertex = v\n",
    "            gamma_max = 1\n",
    "            Away = False\n",
    "        else:\n",
    "            #choose Away direction\n",
    "            d = d_A\n",
    "            vertex = a\n",
    "            gamma_max = alpha_a/(1-alpha_a)\n",
    "            Away = True\n",
    "\n",
    "        #Update next iterate by doing a feasible line-search\n",
    "        # print(type(d), type(x), type(gamma_max))\n",
    "        x, gamma = line_search(np.array(x), np.array(d), gamma_max, func)\n",
    "        #x, gamma = segment_search(func, grad_f, x, x + gamma_max *d)\n",
    "\n",
    "        #update active set\n",
    "        S = update_S(S,gamma, Away, vertex)\n",
    "        \n",
    "        end = process_time()\n",
    "        time.append(time[t] + end - start)\n",
    "        \n",
    "        f_improv = function_value[-1] - func(x)\n",
    "        function_value.append(func(x))\n",
    "        \n",
    "        t+=1\n",
    "        \n",
    "    return x, function_value, time, t, primal_gap, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convex_hull_correction1(S, func):    \n",
    "\n",
    "    M = np.array([np.array(i) for i in S])\n",
    "    \n",
    "    def fun(theta):\n",
    "        return func(np.dot(M.T,theta))\n",
    "\n",
    "    cons = ({'type': 'eq', 'fun': lambda theta: sum(theta) - 1}) #sum of theta = 1\n",
    "    bnds = tuple([(0, 1) for _ in M])\n",
    "    x0 = tuple([1/len(M) for _ in M])\n",
    "\n",
    "    res = minimize(fun, x0, bounds=bnds, constraints=cons)\n",
    "    \n",
    "    final_S = {tuple(M[i]):res.x[i] for i in range(len(M)) if np.round(res.x[i],5) > 0}\n",
    "\n",
    "    return np.dot(M.T,res.x),final_S\n",
    "\n",
    "\n",
    "def convex_hull_correction2(S, q):\n",
    "\n",
    "    M = np.array([np.array(i) for i in S])\n",
    "   \n",
    "    opt, theta = proj_oracle(M,q)\n",
    "    \n",
    "    final_S = {tuple(M[i]):theta[i] for i in range(len(M))if np.round(theta[i],5) > 0}\n",
    "\n",
    "    return opt, final_S\n",
    "\n",
    "\n",
    "def proj_oracle(vertices,y):\n",
    "    m = Model(\"opt\")\n",
    "    n = len(vertices[0])\n",
    "    \n",
    "    #define variables\n",
    "    lam = {}\n",
    "    for i in range(len(vertices)):\n",
    "        lam[i] = m.addVar(lb=0, name='lam_{}'.format(i))\n",
    "    \n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        x.append(m.addVar(lb=-GRB.INFINITY, name='x_{}'.format(i)))\n",
    "    x = np.array(x)\n",
    "    m.update()\n",
    "\n",
    "    objExp = 0.5* np.dot(x-y, x-y)\n",
    "    m.setObjective(objExp, GRB.MINIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    #feasibility constraints\n",
    "    for i in range(n):\n",
    "        m.addConstr(x[i],'=', sum([lam[j]*vertices[j][i] for j in range(len(vertices))]))\n",
    "\n",
    "    #convex hull constraint\n",
    "    m.addConstr(quicksum([lam[i] for i in lam.keys()]), '=',1)\n",
    "    m.update()\n",
    "    \n",
    "    #optimize\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "    m.write('exact.lp')\n",
    "    m.optimize()\n",
    "    return np.array([i.x for i in x]), np.array([lam[i].x for i in lam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_tight(y,g):\n",
    "    \n",
    "    #sort y so we can check feasiblity in the base polytope\n",
    "    pi = np.argsort(-y)+1\n",
    "\n",
    "    #find cummulative sums of sorted vector so we can check feasibility/violations\n",
    "    s = np.cumsum(sorted(y,reverse =True))\n",
    "    violations = np.round(np.array([g[i+1] - j for i,j in enumerate(s)]),6)\n",
    "    \n",
    "    if any (violations < 0):\n",
    "        return 'y not feasible'\n",
    "    elif all(violations > 0):\n",
    "        return [0]\n",
    "    else:\n",
    "        return pi[:np.arange(len(y))[violations==0][-1]+1]\n",
    "\n",
    "    \n",
    "def proj(x):\n",
    "    return 0.5*np.dot(x - y,x-y)\n",
    "\n",
    "\n",
    "def proj_grad(x):\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def chi(M):\n",
    "    chi_0 = np.zeros(n)\n",
    "    for i in M:\n",
    "        chi_0[i-1] = 1\n",
    "    return chi_0\n",
    "\n",
    "\n",
    "def f(s):\n",
    "    return sum([n + 1 - i for i in range(1,s+1)])\n",
    "\n",
    "\n",
    "def compute_M(N,x):\n",
    "    return N[np.round(proj_grad(x)[N - 1],5) == np.round(np.min(proj_grad(x)[N - 1]),5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_oracle(A1,A2,b1,b2, c):\n",
    "    \n",
    "    '''\n",
    "    General form LP solver that solves min c^Tx subject to Ax <= b\n",
    "    '''\n",
    "\n",
    "    m = Model(\"opt\")\n",
    "    n = len(A.T)\n",
    "\n",
    "    #define variables\n",
    "    x = []\n",
    "    for i in range(n):\n",
    "        x.append(m.addVar(lb=-GRB.INFINITY, name='x_{}'.format(i)))\n",
    "\n",
    "    m.update()              \n",
    "\n",
    "    objExp = np.dot(np.array(x),c)\n",
    "    m.setObjective(objExp, GRB.MAXIMIZE)\n",
    "    m.update()\n",
    "\n",
    "    #feasibility constraints\n",
    "    for i in range(len(A1)):\n",
    "        m.addConstr(np.dot(np.array(x),A1[i]),'<=', b1[i])\n",
    "        \n",
    "    for i in range(len(A2)):\n",
    "        m.addConstr(np.dot(np.array(x),A2[i]),'==', b2[i])\n",
    "\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    #convex hull constraint\n",
    "\n",
    "    m.update()\n",
    "\n",
    "    #optimize\n",
    "    m.setParam( 'OutputFlag', False )\n",
    "    m.optimize()\n",
    "\n",
    "    return np.array([i.x for i in x]), m.Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2021-07-09\n",
      "Using license file C:\\Users\\jaimo\\gurobi.lic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-45f628269f31>:23: DeprecationWarning: Deprecated, pass a TempConstr or use Model.addLConstr\n",
      "  opt, theta = proj_oracle(M,q)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1250.625, 314.1875, 129.265625)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from constants import *\n",
    "from submodular_polytope import CardinalitySubmodularFunction, CardinalityPolytope, \\\n",
    "    PermutahedronSubmodularFunction, Permutahedron\n",
    "from utils import generate_random_permutation\n",
    "import random\n",
    "\n",
    "n = 100\n",
    "f = PermutahedronSubmodularFunction(n)\n",
    "P = Permutahedron(f)\n",
    "\n",
    "\n",
    "def generate_loss_function_vector_for_permutahedron(n: int):\n",
    "    x = [random.random() for i in range(n)]         # Each entry is random number between 0 and 1\n",
    "    s = sum(x)\n",
    "    x = [(x[i] * n)/s for i in range(n)]            # Normalize so the sum is always 1\n",
    "    x.sort(reverse=True)\n",
    "    return np.array(x)\n",
    "\n",
    "\n",
    "def generate_losses_and_random_vector(n: int, T: int):\n",
    "    loss_vectors_list = [generate_loss_function_vector_for_permutahedron(n) for i in range(T)]\n",
    "    x = tuple(generate_random_permutation(n))\n",
    "    v = tuple(generate_random_permutation(n))\n",
    "    return loss_vectors_list, x, v\n",
    "\n",
    "\n",
    "def online_mirror_descent_permutahedron(P: Permutahedron, T: int):\n",
    "    \"\"\"\n",
    "    Performs online mirror descent on a permutahedron\n",
    "    :param P: permuathedron. See submodular_polytope.py for class definition\n",
    "    :param T: number of iterations\n",
    "    :return: Total regret\n",
    "    \"\"\"\n",
    "    n = len(P)\n",
    "    D = (n ** 3 - n)/6                  # Diameter of permutahedron\n",
    "    G = n                               # Upper bound on norm l1 norm\n",
    "    alpha = 1                           # For Euclidean projection\n",
    "    eta = (D/G) * math.sqrt((2 * alpha)/T)\n",
    "    \n",
    "    total_time_vanilla, total_time_active_set_optimized, total_time_doubly_optimized = 0.0, 0.0, 0.0\n",
    "    fw_iterations_vanilla, fw_iterations_active_set_optimized, fw_iterations_doubly_optimized = [], [], []\n",
    "    \n",
    "    loss_vectors_list, x_0, v = generate_losses_and_random_vector(n, T)\n",
    "    S_vanilla, S_active_set_optimized, S_doubly_optimized = {x_0: 1}, {x_0: 1}, {x_0: 1}                        # Active vertex set with its coefficients\n",
    "    \n",
    "    # Vanilla FW\n",
    "    for t in range(T):\n",
    "        max_coeff = 0\n",
    "        x = x_0\n",
    "        for sigma in S_vanilla:\n",
    "            if S_vanilla[sigma] > max_coeff:\n",
    "                max_coeff = S_vanilla[sigma]\n",
    "                x = sigma\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(x, l)\n",
    "        y = x - eta * l\n",
    "        \n",
    "        f = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_f = lambda x: np.array(x) - np.array(y)\n",
    "        \n",
    "        def lmo(x):\n",
    "            _, v = P.linear_optimization_over_base(x)\n",
    "            return tuple(v)\n",
    "        \n",
    "        f_tol,time_tol,epsilon = -1, np.inf, 0.1\n",
    "        fw_sol, fw_func, fw_time, fw_iter, fw_gap, S_vanilla = AFW(v, {v: 1}, lmo, epsilon,f,grad_f, f_tol, time_tol)\n",
    "        fw_iterations_vanilla.append(fw_iter)\n",
    "        \n",
    "        total_time_vanilla = total_time_vanilla + sum(fw_time)\n",
    "        \n",
    "    # Active set optimized FW\n",
    "    for t in range(T):\n",
    "        max_coeff = 0\n",
    "        x = x_0\n",
    "        for sigma in S_active_set_optimized:\n",
    "            if S_active_set_optimized[sigma] > max_coeff:\n",
    "                max_coeff = S_active_set_optimized[sigma]\n",
    "                x = sigma\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(x, l)\n",
    "        y = x - eta * l\n",
    "        \n",
    "        f = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_f = lambda x: np.array(x) - np.array(y)\n",
    "        \n",
    "        def lmo(x):\n",
    "            _, v = P.linear_optimization_over_base(x)\n",
    "            return tuple(v)\n",
    "        \n",
    "        f_tol,time_tol,epsilon = -1, np.inf, 0.1\n",
    "        fw_sol, fw_func, fw_time, fw_iter, fw_gap, S_active_set_optimized = AFW(x, S_active_set_optimized, lmo, epsilon,f,grad_f, f_tol, time_tol)\n",
    "        \n",
    "        fw_iterations_active_set_optimized.append(fw_iter)\n",
    "        total_time_active_set_optimized = total_time_active_set_optimized + sum(fw_time)\n",
    "                \n",
    "    # Doubly optimized FW\n",
    "    for t in range(T):\n",
    "        max_coeff = 0\n",
    "        x = x_0\n",
    "        for sigma in S_doubly_optimized:\n",
    "            if S_doubly_optimized[sigma] > max_coeff:\n",
    "                max_coeff = S_doubly_optimized[sigma]\n",
    "                x = sigma\n",
    "\n",
    "        l = loss_vectors_list[t]\n",
    "        loss = np.dot(x, l)\n",
    "        y = x - eta * l\n",
    "        \n",
    "        f = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_f = lambda x: np.array(x) - np.array(y)\n",
    "        \n",
    "        def lmo(x):\n",
    "            _, v = P.linear_optimization_over_base(x)\n",
    "            return tuple(v)\n",
    "        \n",
    "        f_tol,time_tol,epsilon = -1, np.inf, 0.1\n",
    "        x, S_doubly_optimized = convex_hull_correction2(S_doubly_optimized, y)\n",
    "        fw_sol, fw_func, fw_time, fw_iter, fw_gap, S_doubly_optimized = AFW(x, S_doubly_optimized, lmo, epsilon,f,grad_f, f_tol, time_tol)\n",
    "        \n",
    "        fw_iterations_doubly_optimized.append(fw_iter)\n",
    "        total_time_doubly_optimized = total_time_doubly_optimized + sum(fw_time)\n",
    "        \n",
    "    return total_time_vanilla, total_time_active_set_optimized, total_time_doubly_optimized\n",
    "\n",
    "online_mirror_descent_permutahedron(P, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "50\n",
      "53\n",
      "55\n",
      "30\n",
      "24\n",
      "37\n",
      "30\n",
      "31\n",
      "30\n",
      "30\n",
      "37\n",
      "33\n",
      "32\n",
      "26\n",
      "30\n",
      "29\n",
      "29\n",
      "32\n",
      "30\n",
      "32\n",
      "30\n",
      "37\n",
      "27\n",
      "30\n",
      "28\n",
      "31\n",
      "28\n",
      "31\n",
      "35\n",
      "23\n",
      "28\n",
      "31\n",
      "31\n",
      "38\n",
      "26\n",
      "30\n",
      "36\n",
      "27\n",
      "32\n",
      "32\n",
      "34\n",
      "23\n",
      "23\n",
      "32\n",
      "29\n",
      "27\n",
      "30\n",
      "29\n",
      "26\n",
      "30\n",
      "37\n",
      "30\n",
      "31\n",
      "30\n",
      "28\n",
      "42\n",
      "23\n",
      "29\n",
      "31\n",
      "31\n",
      "30\n",
      "29\n",
      "26\n",
      "30\n",
      "30\n",
      "37\n",
      "30\n",
      "23\n",
      "33\n",
      "44\n",
      "30\n",
      "38\n",
      "31\n",
      "30\n",
      "30\n",
      "40\n",
      "24\n",
      "27\n",
      "37\n",
      "30\n",
      "29\n",
      "31\n",
      "28\n",
      "22\n",
      "30\n",
      "40\n",
      "30\n",
      "25\n",
      "32\n",
      "28\n",
      "34\n",
      "30\n",
      "30\n",
      "29\n",
      "30\n",
      "23\n",
      "36\n",
      "27\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101.640625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def online_mirror_descent_permutahedron_optimized(P: Permutahedron, T: int):\n",
    "    \"\"\"\n",
    "    Performs online mirror descent on a permutahedron\n",
    "    :param P: permuathedron. See submodular_polytope.py for class definition\n",
    "    :param T: number of iterations\n",
    "    :return: Total regret\n",
    "    \"\"\"\n",
    "    n = len(P)\n",
    "    D = (n ** 3 - n)/6                  # Diameter of permutahedron\n",
    "    G = n                               # Upper bound on norm l1 norm\n",
    "    alpha = 1                           # For Euclidean projection\n",
    "    eta = (D/G) * math.sqrt((2 * alpha)/T)\n",
    "    total_time = 0\n",
    "\n",
    "    v = tuple(generate_random_permutation(n))\n",
    "    x_0 = generate_random_permutation(n)\n",
    "    S = {tuple(x_0): 1}                        # Active vertex set with its coefficients\n",
    "    for t in range(T):\n",
    "        max_coeff = 0\n",
    "        x = x_0\n",
    "        for sigma in S:\n",
    "            if S[sigma] > max_coeff:\n",
    "                max_coeff = S[sigma]\n",
    "                x = sigma\n",
    "\n",
    "        l = generate_loss_function_vector_for_permutahedron(n)\n",
    "        loss = np.dot(x, l)\n",
    "        y = x - eta * l\n",
    "        # print(y)\n",
    "        f = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_f = lambda x: np.array(x) - np.array(y)\n",
    "        def lmo(x):\n",
    "            _, v = P.linear_optimization_over_base(x)\n",
    "            return tuple(v)\n",
    "        f_tol,time_tol,epsilon = -1, np.inf, 0.1\n",
    "        \n",
    "        # x, S = convex_hull_correction2(S, y)\n",
    "        AFW_sol, AFW_func, AFW_time, AFW_iter,AFW_gap, S = AFW(x, S, lmo, epsilon,f,grad_f, f_tol, time_tol)\n",
    "        # print(sum(AFW_time))\n",
    "        print(AFW_iter)\n",
    "        total_time = total_time + sum(AFW_time)\n",
    "\n",
    "    return total_time\n",
    "\n",
    "\n",
    "\n",
    "online_mirror_descent_permutahedron_vanilla(P, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "61\n",
      "27\n",
      "10\n",
      "7\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.015625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_mirror_descent_permutahedron_optimized(P, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-45f628269f31>:23: DeprecationWarning: Deprecated, pass a TempConstr or use Model.addLConstr\n",
      "  opt, theta = proj_oracle(M,q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "44\n",
      "34\n",
      "17\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.734375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def online_mirror_descent_permutahedron_doubly_optimized(P: Permutahedron, T: int):\n",
    "    \"\"\"\n",
    "    Performs online mirror descent on a permutahedron\n",
    "    :param P: permuathedron. See submodular_polytope.py for class definition\n",
    "    :param T: number of iterations\n",
    "    :return: Total regret\n",
    "    \"\"\"\n",
    "    n = len(P)\n",
    "    D = (n ** 3 - n)/6                  # Diameter of permutahedron\n",
    "    G = n                               # Upper bound on norm l1 norm\n",
    "    alpha = 1                           # For Euclidean projection\n",
    "    eta = (D/G) * math.sqrt((2 * alpha)/T)\n",
    "    total_time = 0\n",
    "\n",
    "    v = tuple(generate_random_permutation(n))\n",
    "    x_0 = generate_random_permutation(n)\n",
    "    S = {tuple(x_0): 1}                        # Active vertex set with its coefficients\n",
    "    for t in range(T):\n",
    "        max_coeff = 0\n",
    "        x = x_0\n",
    "        for sigma in S:\n",
    "            if S[sigma] > max_coeff:\n",
    "                max_coeff = S[sigma]\n",
    "                x = sigma\n",
    "\n",
    "        l = generate_loss_function_vector_for_permutahedron(n)\n",
    "        loss = np.dot(x, l)\n",
    "        y = x - eta * l\n",
    "        # print(y)\n",
    "        f = lambda x: 0.5 * np.dot(x - y, x - y)\n",
    "        grad_f = lambda x: np.array(x) - np.array(y)\n",
    "        def lmo(x):\n",
    "            _, v = P.linear_optimization_over_base(x)\n",
    "            return tuple(v)\n",
    "        f_tol,time_tol,epsilon = -1, np.inf, 0.1\n",
    "        \n",
    "        x, S = convex_hull_correction2(S, y)\n",
    "        AFW_sol, AFW_func, AFW_time, AFW_iter,AFW_gap, S = AFW(x, S, lmo, epsilon,f,grad_f, f_tol, time_tol)\n",
    "        # print(sum(AFW_time))\n",
    "        print(AFW_iter)\n",
    "        total_time = total_time + sum(AFW_time)\n",
    "\n",
    "    return total_time\n",
    "\n",
    "online_mirror_descent_permutahedron_doubly_optimized(P, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}